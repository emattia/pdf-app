{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eddie/micromamba/envs/pdf-dev/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import requests\n",
    "\n",
    "\n",
    "try:\n",
    "    import pymupdf as fitz  # available with v1.24.3\n",
    "except ImportError:\n",
    "    import fitz\n",
    "\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from fitz import Document as FitzDocument\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"./pdfs/outerbounds-brief.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(pdf_path)\n",
    "assert doc.is_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 18\n",
      "Metadata: {'author': '',\n",
      " 'creationDate': \"D:20240130113640-08'00'\",\n",
      " 'creator': 'Acrobat Pro 23.8.20470',\n",
      " 'encryption': None,\n",
      " 'format': 'PDF 1.7',\n",
      " 'keywords': '',\n",
      " 'modDate': \"D:20240130113744-08'00'\",\n",
      " 'producer': 'Acrobat Pro 23.8.20470',\n",
      " 'subject': '',\n",
      " 'title': '',\n",
      " 'trapped': ''}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of pages: {doc.page_count}\")\n",
    "print(f\"Metadata: \", end=\"\")\n",
    "pprint(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 'Cover', 1],\n",
      " [1, '1', 2],\n",
      " [1, '2', 3],\n",
      " [1, '3', 4],\n",
      " [1, '4', 5],\n",
      " [1, '5', 6],\n",
      " [1, '6', 7],\n",
      " [1, '7', 8],\n",
      " [1, '8', 9],\n",
      " [1, '9', 10],\n",
      " [1, '10', 11],\n",
      " [1, '11', 12],\n",
      " [1, '12', 13],\n",
      " [1, '13', 14],\n",
      " [1, '14', 15],\n",
      " [1, '15', 16],\n",
      " [1, '16', 17],\n",
      " [1, 'Back', 18]]\n"
     ]
    }
   ],
   "source": [
    "pprint(doc.get_toc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def pdf_to_text(path, start_page=1, end_page=None):\n",
    "    doc = fitz.open(path)\n",
    "    total_pages = doc.page_count\n",
    "    if end_page is None:\n",
    "        end_page = total_pages\n",
    "    text_list = []\n",
    "    for i in range(start_page - 1, end_page):\n",
    "        text = doc.load_page(i).get_text(\"text\")\n",
    "        text = preprocess(text)\n",
    "        text_list.append({\"content\": text, \"page\": i + 1})\n",
    "    doc.close()\n",
    "    return text_list\n",
    "\n",
    "\n",
    "def text_to_chunks(texts, word_length=150, start_page=1):\n",
    "    text_toks = [(t[\"content\"].split(\" \"), t[\"page\"]) for t in texts]\n",
    "    chunks = []\n",
    "\n",
    "    for idx, words_and_page in enumerate(text_toks):\n",
    "        words = words_and_page[0]\n",
    "        page = words_and_page[1]\n",
    "        for i in range(0, len(words), word_length):\n",
    "            chunk = words[i : i + word_length]\n",
    "            if (\n",
    "                (i + word_length) > len(words)\n",
    "                and (len(chunk) < word_length)\n",
    "                and (len(text_toks) != (idx + 1))\n",
    "            ):\n",
    "                # text_toks[idx + 1] = chunk + text_toks[idx + 1]\n",
    "                text_toks[idx + 1] = (\n",
    "                    chunk + text_toks[idx + 1][0],\n",
    "                    text_toks[idx + 1][1],\n",
    "                )\n",
    "                continue\n",
    "            chunk = \" \".join(chunk).strip()\n",
    "            chunk = f\"[Page no. {idx+start_page}]\" + \" \" + '\"' + chunk + '\"'\n",
    "            chunks.append((chunk, page))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_EMBEDDING_MODEL_INFO = {\n",
    "    \"model_name\": \"all-MiniLM-L6-v2\",\n",
    "    \"model_framework\": \"sentence-transformers\",\n",
    "    \"pretrained_model_provider\": \"Hugging Face\",\n",
    "    \"use_case\": \"text-semantic-search\",\n",
    "}\n",
    "\n",
    "\n",
    "class SemanticSearchModel:\n",
    "    \"\"\"\n",
    "    Manager for a semantic search model.\n",
    "\n",
    "    args:\n",
    "        None\n",
    "\n",
    "    methods:\n",
    "        fit(data: List[str], batch: int, n_neighbors: int) -> None:\n",
    "            Fits the model M with the data.\n",
    "        _get_text_embedding(texts: List[str], batch: int) -> np.ndarray:\n",
    "            Returns the embeddings of the text.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.embedding_model = SentenceTransformer(\n",
    "            TEXT_EMBEDDING_MODEL_INFO[\"model_name\"]\n",
    "        )\n",
    "        self.fitted = False\n",
    "\n",
    "    def _get_text_embedding(self, texts, batch_size=1000):\n",
    "        \"\"\"\n",
    "        Gather a stack of embedded texts, packed batch_size at a time.\n",
    "        \"\"\"\n",
    "        embeddings = []\n",
    "        n_texts = len(texts)\n",
    "        for batch_start_idx in range(0, n_texts, batch_size):\n",
    "            text_batch = texts[batch_start_idx : (batch_start_idx + batch_size)]\n",
    "            embedding_batch = self.embedding_model.encode(text_batch)\n",
    "            embeddings.append(embedding_batch)\n",
    "        print(\"[DEBUG] Embedding batches:\", len(embeddings))\n",
    "        embeddings = np.vstack(embeddings)\n",
    "        print(\"[DEBUG] Embedding reshaped:\", embeddings.shape)\n",
    "        return embeddings\n",
    "\n",
    "    def fit(self, data, batch_size=1000, n_neighbors=6):\n",
    "        \"\"\"\n",
    "        The only public method in this class.\n",
    "        Fits the model with the data when a new PDF is uploaded.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.embeddings = self._get_text_embedding(data, batch_size=batch_size)\n",
    "        n_neighbors = min(n_neighbors, len(self.embeddings))\n",
    "        print(\n",
    "            \"[DEBUG] Fitting Nearest Neighbors model with %s neighbors.\" % n_neighbors\n",
    "        )\n",
    "        self.nn = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "        self.nn.fit(self.embeddings)\n",
    "        print(\"[DEBUG] Fit complete.\")\n",
    "        self.fitted = True\n",
    "\n",
    "    def __call__(self, text, return_data=True):\n",
    "        \"\"\"\n",
    "        Inference time method.\n",
    "        Return the nearest neighbors of a new text.\n",
    "        \"\"\"\n",
    "        print(\"[DEBUG] Getting nearest neighbors of text:\", text)\n",
    "        embedding = self.embedding_model.encode([text])\n",
    "        print(\"[DEBUG] Embedding:\", embedding.shape)\n",
    "        neighbors = self.nn.kneighbors(embedding, return_distance=False)[0]\n",
    "        if return_data:\n",
    "            return [self.data[text_neighbs] for text_neighbs in neighbors]\n",
    "        else:\n",
    "            return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ls = pdf_to_text(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'ML/January 2024 A developer-friendly platform for ML+AI systems ',\n",
       "  'page': 1},\n",
       " {'content': 'Background 1 Outerbounds was spun off from Netflix in 2021. At Netflix, Outerbounds’ founders led ML and AI infrastructure, encoding the best practices of rapid ML/ AI development into an open-source library Metaflow, with a particular focus on human-centric, productivity- boosting developer experience. In addition to powering most ML/AI projects at Netflix today, Metaflow has become an industry-standard tool for production ML/AI systems, adopted by hundreds of leading companies. It powers a wide range of use cases from financial fraud detection and biotech to autonomous drones and custom large language models. Outerbounds builds on the foundation laid by Metaflow by offering it as a part of a fully managed, secure, cost- effective ML and AI platform. ',\n",
       "  'page': 2},\n",
       " {'content': 'Scenario Continuously updating ML with structured data 2 Let’s take a look at a typical business-oriented ML system. The system ingests data from a data warehouse, trains models for classification or forecasting, and uses them to provide up-to-date inferences, integrating results to surrounding systems. Consider common questions that raise during development of a system like this. The challenge is not to ship the above system once, but to develop systems like this routinely, continuously improving results. How to interface data engineering and ML workflows? ML-specific ETL ETL How to allow rapid development of models and features? How to experiment and train models at scale, leveraging the cloud cost-efficiently? How to keep track of all code, data, and models, enabling continuous improvement? Feature Transformations Data exploration Train models Model experiment Batch inference Model registry How to integrate the results into surrounding systems reliably and operate them effortlessly? Production integrations Operations How to deploy all of the above in production in a highly-available manner? Scheduled Execution Monitor Alert How to access data quickly and securely? ',\n",
       "  'page': 3},\n",
       " {'content': 'Based on our experience from working with hundreds of companies, real-world ML and AI systems end up including a these four foundational layers of infrastructure - sometimes organically, sometimes by design: There are many valid technical solutions to each of these layers. While not all approaches are equal, ultimately human factors - the ease of experimentation, development, and operations - tend to dominate the effectiveness of the overall solution. Outerbounds provides a full stack of ML/AI infrastructure, addressing the above layers holistically - take a look how. Accessing data efficiently and securely. Data Leveraging compute resources to process data, train models, and run inference. Compute Orchestrating the system, keeping it running in a highly- available manner. Orchestration Observing and keeping track of code, data, and models across experiments and production. Tracking and Versioning Enabling developers to experiment rapidly, develop effectively, ship to production confidently, and improve results continuously. Developer UX 3 Solution Human-Centric Infrastructure for ML and AI ',\n",
       "  'page': 4},\n",
       " {'content': 'Data 4 Outerbounds integrates to popular data lakes and warehouses which excel at storing and processing structured data. Access data quickly and securely, interface with ETL, process features, and use modern tools for data, while building ML/AI systems cost-efficiently. With a few lines of Python code, you can read data securely from various data sources, following preconfigured paved paths that conform with policies. Workflows can be configured to run automatically whenever new data is available, enabling continuous training and inference. Load both structured and unstructured data at blazing speeds, up to tens of gigabits per second, using a built-in, high-performance data layer. Divide responsibilities clearly between data engineering and ML/AI/data science teams, balancing stability and experimentation. @trigger = ( ): @secrets @snowflake @step start : = .next( .end) \"data_update\" class def self self.x 124 self self (event ) ( ) DataFlow FlowSpec Decoding Parquet from datastore, Gbit/s Small (disk) Medium (disk) Macbook Pro (disk) Medium (tmpfs) Large (tmpfs) Recent runs: Last deployed 7 days ago: 2023-10-18 1:43pm by shri@outerbounds.co Triggered by events: metaflow.PreprocessingFlow Production token: ••••• Show trainingflow Latest run succeeded trainingflow/argo-trainingflow-phn7w Event Trigger: metaflow.PreprocessingFlow Started at: 2023-03-12, 4:40pm Fast data path ETL Project-specific tables/data Authoritative fact tables ML/AI workflow Raw data Project-specific ETL ',\n",
       "  'page': 5}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_ls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_to_chunks(text_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[Page no. 3] \"ML/January 2024 A developer-friendly platform for ML+AI systems  Background 1 Outerbounds was spun off from Netflix in 2021. At Netflix, Outerbounds’ founders led ML and AI infrastructure, encoding the best practices of rapid ML/ AI development into an open-source library Metaflow, with a particular focus on human-centric, productivity- boosting developer experience. In addition to powering most ML/AI projects at Netflix today, Metaflow has become an industry-standard tool for production ML/AI systems, adopted by hundreds of leading companies. It powers a wide range of use cases from financial fraud detection and biotech to autonomous drones and custom large language models. Outerbounds builds on the foundation laid by Metaflow by offering it as a part of a fully managed, secure, cost- effective ML and AI platform.  Scenario Continuously updating ML with structured data 2 Let’s take a look at a typical business-oriented ML system. The system ingests data from a\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(chunks[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = SemanticSearchModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Embedding batches: 1\n",
      "[DEBUG] Embedding reshaped: (18, 384)\n",
      "[DEBUG] Fitting Nearest Neighbors model with 6 neighbors.\n",
      "[DEBUG] Fit complete.\n"
     ]
    }
   ],
   "source": [
    "recommender.fit([c[0] for c in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What does Outerbounds do?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Getting nearest neighbors of text: What does Outerbounds do?\n",
      "[DEBUG] Embedding: (1, 384)\n"
     ]
    }
   ],
   "source": [
    "topn_chunks = recommender(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[Page no. 4] \"Based on our experience from working with hundreds of companies, real-world ML and AI systems end up including a these four foundational layers of infrastructure - sometimes organically, sometimes by design: There are many valid technical solutions to each of these layers. While not all approaches are equal, ultimately human factors - the ease of experimentation, development, and operations - tend to dominate the effectiveness of the overall solution. Outerbounds provides a full stack of ML/AI infrastructure, addressing the above layers holistically - take a look how. Accessing data efficiently and securely. Data Leveraging compute resources to process data, train models, and run inference. Compute Orchestrating the system, keeping it running in a highly- available manner. Orchestration Observing and keeping track of code, data, and models across experiments and production. Tracking and Versioning Enabling developers to experiment rapidly, develop effectively, ship to production confidently, and improve results continuously. Developer UX\"',\n",
       " '[Page no. 9] \"data 1  Modeling Deployment Versioning Orchestration Compute Data 8 Boost productivity and happiness with Delightful developer experience Instead of having to navigate disparate tools, Outerbounds offers a single developer-friendly API and a coherent UI covering the full ML and AI stack, so developers with diverse expertise can focus on building and deploying systems rapidly. Gone are the days when AI/ML systems were treated as islands, separate from other production systems. Today’s systems are built on infrastructure and policies which make DevOps, SREs, and other engineers happy too. Outerbounds has increased our appetite for model based solutions. We can use ML in places where we hadn’t considered using it before, now that we know that we can have a reliable model in production quickly. Thanasis Noulas Our goal has been maximizing the utilization of AWS resources and therefore minimizing costs. For us, Outerbounds is a very big efficiency gain, just\"',\n",
       " '[Page no. 3] \"ML/January 2024 A developer-friendly platform for ML+AI systems  Background 1 Outerbounds was spun off from Netflix in 2021. At Netflix, Outerbounds’ founders led ML and AI infrastructure, encoding the best practices of rapid ML/ AI development into an open-source library Metaflow, with a particular focus on human-centric, productivity- boosting developer experience. In addition to powering most ML/AI projects at Netflix today, Metaflow has become an industry-standard tool for production ML/AI systems, adopted by hundreds of leading companies. It powers a wide range of use cases from financial fraud detection and biotech to autonomous drones and custom large language models. Outerbounds builds on the foundation laid by Metaflow by offering it as a part of a fully managed, secure, cost- effective ML and AI platform.  Scenario Continuously updating ML with structured data 2 Let’s take a look at a typical business-oriented ML system. The system ingests data from a\"',\n",
       " '[Page no. 18] \"Smarter machines, built by happier humans outerbounds.com sales@outerbounds.co\"',\n",
       " '[Page no. 15] \"gaurav@company.com View hugo@company.com Execute jane@company.com View Humans A Pickle Perimeter CPU utilization Memory utilization Flows We are a bank, everything we do needs to be auditable. This means we need to be able to reproduce everything that has been in production. Outerbounds gives us that for free, as all models and metadata are versioned. I sleep much more comfortably knowing this. Thanasis Noulas  outerbounds.com sales@outerbounds.co Get started with free 30 day trial Outerbounds has proven to be transformative for us The ability to scale our operations both vertically and horizontally, and launch parallel experiments and pipelines, has made Metaflow and Outerbounds an appealing choice for our ML team, significantly enhancing our productivity, without the burden of worrying about infra. Soma S Dhavala 13 Develop ML/AI systems, not just models Seamless data integrations Production-grade orchestration Cost-efficient compute at scale Built-in tracking and versioning  12 Appendix Outerbounds vs. Open-Source Metaflow\"',\n",
       " '[Page no. 15] \"How does the managed Outerbounds platform differ from open-source Metaflow? Outerbounds Developer-friendly API Same open-source Metaflow Yes Yes Yes Yes Basic version in OSS Basic version in OSS Basic version in OSS Basic version in OSS Included Included Included Included Included Included Included Included Included Included Included Included w/ additional features Managed and optimized Managed and optimized Same open-source Metaflow Same open-source Metaflow Same open-source Metaflow Same open-source Metaflow No lock-in, build apps with open-source APIs Version and track everything Simple access to scalable compute Deploy to production with a single click Deploys securely in your cloud account Unlimited compute at no extra cost Secure data integrations Scalable compute backend Highly-available production orchestration Durable metadata Cloud workstations Comprehensive UI Multi-cloud compute Platform- and task-level performance metrics Cost tracking and optimization Auth via SSO and machine tokens Role-Based Access Control Multiple isolated environments Audit logs Fully managed with 24/7 dedicated support\"']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topn_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[Page no. 15] \"How does the managed Outerbounds platform differ from open-source Metaflow? Outerbounds Developer-friendly API Same open-source Metaflow Yes Yes Yes Yes Basic version in OSS Basic version in OSS Basic version in OSS Basic version in OSS Included Included Included Included Included Included Included Included Included Included Included Included w/ additional features Managed and optimized Managed and optimized Same open-source Metaflow Same open-source Metaflow Same open-source Metaflow Same open-source Metaflow No lock-in, build apps with open-source APIs Version and track everything Simple access to scalable compute Deploy to production with a single click Deploys securely in your cloud account Unlimited compute at no extra cost Secure data integrations Scalable compute backend Highly-available production orchestration Durable metadata Cloud workstations Comprehensive UI Multi-cloud compute Platform- and task-level performance metrics Cost tracking and optimization Auth via SSO and machine tokens Role-Based Access Control Multiple isolated environments Audit logs Fully managed with 24/7 dedicated support\"',\n",
       " 15)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\n",
    "prompt += \"search results:\\n\\n\"\n",
    "for c in topn_chunks:\n",
    "    prompt += c + \"\\n\\n\"\n",
    "\n",
    "# stolen: https://github.com/bhaskatripathi/pdfGPT/blob/main/api.py#L137C5-L146C6\n",
    "prompt += (\n",
    "    \"Instructions: Only reply to the query based on the search results given. \"\n",
    "    \"Cite each reference using [ Page Number ] notation \"\n",
    "    \"(every result has this number at the beginning). \"\n",
    "    \"Weave responses into a coherent and succinct paragraph. \"\n",
    "    \"Citation should be done in the same words that it refers to in Markdown. \"\n",
    "    \"Only include information found in the results and \"\n",
    "    \"Only answer what is asked. The answer should be short and concise. \"\n",
    "    \"Return a JSON object with the following format: \\n\\n\"\n",
    "    \"{\\n\"\n",
    "    f'  \"query\": \"{question}\",\\n'\n",
    "    '  \"answer\": \"Answer here.\"\\n'\n",
    "    \"}\\n\\n\"\n",
    "    \"Answer step-by-step. Include the page number in the most relevant citations. \"\n",
    "    \"\\n\\n{\\n\"\n",
    "    f'  \"query\": \"{question}\",\\n'\n",
    "    '  \"answer\":'\n",
    "    \"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search results:\n",
      "\n",
      "[Page no. 4] \"Based on our experience from working with hundreds of companies, real-world ML and AI systems end up including a these four foundational layers of infrastructure - sometimes organically, sometimes by design: There are many valid technical solutions to each of these layers. While not all approaches are equal, ultimately human factors - the ease of experimentation, development, and operations - tend to dominate the effectiveness of the overall solution. Outerbounds provides a full stack of ML/AI infrastructure, addressing the above layers holistically - take a look how. Accessing data efficiently and securely. Data Leveraging compute resources to process data, train models, and run inference. Compute Orchestrating the system, keeping it running in a highly- available manner. Orchestration Observing and keeping track of code, data, and models across experiments and production. Tracking and Versioning Enabling developers to experiment rapidly, develop effectively, ship to production confidently, and improve results continuously. Developer UX\"\n",
      "\n",
      "[Page no. 9] \"data 1  Modeling Deployment Versioning Orchestration Compute Data 8 Boost productivity and happiness with Delightful developer experience Instead of having to navigate disparate tools, Outerbounds offers a single developer-friendly API and a coherent UI covering the full ML and AI stack, so developers with diverse expertise can focus on building and deploying systems rapidly. Gone are the days when AI/ML systems were treated as islands, separate from other production systems. Today’s systems are built on infrastructure and policies which make DevOps, SREs, and other engineers happy too. Outerbounds has increased our appetite for model based solutions. We can use ML in places where we hadn’t considered using it before, now that we know that we can have a reliable model in production quickly. Thanasis Noulas Our goal has been maximizing the utilization of AWS resources and therefore minimizing costs. For us, Outerbounds is a very big efficiency gain, just\"\n",
      "\n",
      "[Page no. 3] \"ML/January 2024 A developer-friendly platform for ML+AI systems  Background 1 Outerbounds was spun off from Netflix in 2021. At Netflix, Outerbounds’ founders led ML and AI infrastructure, encoding the best practices of rapid ML/ AI development into an open-source library Metaflow, with a particular focus on human-centric, productivity- boosting developer experience. In addition to powering most ML/AI projects at Netflix today, Metaflow has become an industry-standard tool for production ML/AI systems, adopted by hundreds of leading companies. It powers a wide range of use cases from financial fraud detection and biotech to autonomous drones and custom large language models. Outerbounds builds on the foundation laid by Metaflow by offering it as a part of a fully managed, secure, cost- effective ML and AI platform.  Scenario Continuously updating ML with structured data 2 Let’s take a look at a typical business-oriented ML system. The system ingests data from a\"\n",
      "\n",
      "[Page no. 18] \"Smarter machines, built by happier humans outerbounds.com sales@outerbounds.co\"\n",
      "\n",
      "[Page no. 15] \"gaurav@company.com View hugo@company.com Execute jane@company.com View Humans A Pickle Perimeter CPU utilization Memory utilization Flows We are a bank, everything we do needs to be auditable. This means we need to be able to reproduce everything that has been in production. Outerbounds gives us that for free, as all models and metadata are versioned. I sleep much more comfortably knowing this. Thanasis Noulas  outerbounds.com sales@outerbounds.co Get started with free 30 day trial Outerbounds has proven to be transformative for us The ability to scale our operations both vertically and horizontally, and launch parallel experiments and pipelines, has made Metaflow and Outerbounds an appealing choice for our ML team, significantly enhancing our productivity, without the burden of worrying about infra. Soma S Dhavala 13 Develop ML/AI systems, not just models Seamless data integrations Production-grade orchestration Cost-efficient compute at scale Built-in tracking and versioning  12 Appendix Outerbounds vs. Open-Source Metaflow\"\n",
      "\n",
      "[Page no. 15] \"How does the managed Outerbounds platform differ from open-source Metaflow? Outerbounds Developer-friendly API Same open-source Metaflow Yes Yes Yes Yes Basic version in OSS Basic version in OSS Basic version in OSS Basic version in OSS Included Included Included Included Included Included Included Included Included Included Included Included w/ additional features Managed and optimized Managed and optimized Same open-source Metaflow Same open-source Metaflow Same open-source Metaflow Same open-source Metaflow No lock-in, build apps with open-source APIs Version and track everything Simple access to scalable compute Deploy to production with a single click Deploys securely in your cloud account Unlimited compute at no extra cost Secure data integrations Scalable compute backend Highly-available production orchestration Durable metadata Cloud workstations Comprehensive UI Multi-cloud compute Platform- and task-level performance metrics Cost tracking and optimization Auth via SSO and machine tokens Role-Based Access Control Multiple isolated environments Audit logs Fully managed with 24/7 dedicated support\"\n",
      "\n",
      "Instructions: Only reply to the query based on the search results given. Cite each reference using [ Page Number ] notation (every result has this number at the beginning). Weave responses into a coherent and succinct paragraph. Citation should be done in the same words that it refers to in Markdown. Only include information found in the results and Only answer what is asked. The answer should be short and concise. Return a JSON object with the following format: \n",
      "\n",
      "{\n",
      "  \"query\": \"What does Outerbounds do?\",\n",
      "  \"answer\": \"Answer here.\"\n",
      "}\n",
      "\n",
      "Answer step-by-step. Include the page number in the most relevant citations. \n",
      "\n",
      "{\n",
      "  \"query\": \"What does Outerbounds do?\",\n",
      "  \"answer\":\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an elite professor specializing in machine learning. \"\n",
    "        + \"Discuss topics related to the search results, and no others.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\", messages=message_history, response_format={\"type\": \"json_object\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What does Outerbounds do?',\n",
       " 'answer': 'Outerbounds provides a comprehensive ML/AI infrastructure that includes data access, compute resources, orchestration, and tracking/versioning. It offers a developer-friendly platform to enhance experimentation, development, and production workflows with a single API and coherent UI. Originally spun off from Netflix in 2021, it builds on the open-source Metaflow library to offer a fully managed, secure, and cost-effective platform for a wide range of use cases, including financial fraud detection, biotech, autonomous drones, and large language models [ Page no. 3 ][ Page no. 4 ][ Page no. 9 ][ Page no. 15 ].'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json.loads(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch remote data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "\n",
    "def download(url: str, path: str) -> FitzDocument:\n",
    "    subprocess.run(\n",
    "        [\"wget\", \"--user-agent\", \"Mozilla\", url, \"-O\", path],\n",
    "        stdout=subprocess.DEVNULL,\n",
    "        stderr=subprocess.DEVNULL,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path=\"pdfs/llama2.pdf\"\n",
    "download_and_open(\"https://arxiv.org/pdf/2307.09288.pdf\", path)\n",
    "pdf = fitz.open(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search results:\n",
      "\n",
      "[Page no. 4] \"Based on our experience from working with hundreds of companies, real-world ML and AI systems end up including a these four foundational layers of infrastructure - sometimes organically, sometimes by design: There are many valid technical solutions to each of these layers. While not all approaches are equal, ultimately human factors - the ease of experimentation, development, and operations - tend to dominate the effectiveness of the overall solution. Outerbounds provides a full stack of ML/AI infrastructure, addressing the above layers holistically - take a look how. Accessing data efficiently and securely. Data Leveraging compute resources to process data, train models, and run inference. Compute Orchestrating the system, keeping it running in a highly- available manner. Orchestration Observing and keeping track of code, data, and models across experiments and production. Tracking and Versioning Enabling developers to experiment rapidly, develop effectively, ship to production confidently, and improve results continuously. Developer UX\"\n",
      "\n",
      "[Page no. 9] \"data 1  Modeling Deployment Versioning Orchestration Compute Data 8 Boost productivity and happiness with Delightful developer experience Instead of having to navigate disparate tools, Outerbounds offers a single developer-friendly API and a coherent UI covering the full ML and AI stack, so developers with diverse expertise can focus on building and deploying systems rapidly. Gone are the days when AI/ML systems were treated as islands, separate from other production systems. Today’s systems are built on infrastructure and policies which make DevOps, SREs, and other engineers happy too. Outerbounds has increased our appetite for model based solutions. We can use ML in places where we hadn’t considered using it before, now that we know that we can have a reliable model in production quickly. Thanasis Noulas Our goal has been maximizing the utilization of AWS resources and therefore minimizing costs. For us, Outerbounds is a very big efficiency gain, just\"\n",
      "\n",
      "[Page no. 3] \"ML/January 2024 A developer-friendly platform for ML+AI systems  Background 1 Outerbounds was spun off from Netflix in 2021. At Netflix, Outerbounds’ founders led ML and AI infrastructure, encoding the best practices of rapid ML/ AI development into an open-source library Metaflow, with a particular focus on human-centric, productivity- boosting developer experience. In addition to powering most ML/AI projects at Netflix today, Metaflow has become an industry-standard tool for production ML/AI systems, adopted by hundreds of leading companies. It powers a wide range of use cases from financial fraud detection and biotech to autonomous drones and custom large language models. Outerbounds builds on the foundation laid by Metaflow by offering it as a part of a fully managed, secure, cost- effective ML and AI platform.  Scenario Continuously updating ML with structured data 2 Let’s take a look at a typical business-oriented ML system. The system ingests data from a\"\n",
      "\n",
      "[Page no. 18] \"Smarter machines, built by happier humans outerbounds.com sales@outerbounds.co\"\n",
      "\n",
      "[Page no. 15] \"gaurav@company.com View hugo@company.com Execute jane@company.com View Humans A Pickle Perimeter CPU utilization Memory utilization Flows We are a bank, everything we do needs to be auditable. This means we need to be able to reproduce everything that has been in production. Outerbounds gives us that for free, as all models and metadata are versioned. I sleep much more comfortably knowing this. Thanasis Noulas  outerbounds.com sales@outerbounds.co Get started with free 30 day trial Outerbounds has proven to be transformative for us The ability to scale our operations both vertically and horizontally, and launch parallel experiments and pipelines, has made Metaflow and Outerbounds an appealing choice for our ML team, significantly enhancing our productivity, without the burden of worrying about infra. Soma S Dhavala 13 Develop ML/AI systems, not just models Seamless data integrations Production-grade orchestration Cost-efficient compute at scale Built-in tracking and versioning  12 Appendix Outerbounds vs. Open-Source Metaflow\"\n",
      "\n",
      "[Page no. 15] \"How does the managed Outerbounds platform differ from open-source Metaflow? Outerbounds Developer-friendly API Same open-source Metaflow Yes Yes Yes Yes Basic version in OSS Basic version in OSS Basic version in OSS Basic version in OSS Included Included Included Included Included Included Included Included Included Included Included Included w/ additional features Managed and optimized Managed and optimized Same open-source Metaflow Same open-source Metaflow Same open-source Metaflow Same open-source Metaflow No lock-in, build apps with open-source APIs Version and track everything Simple access to scalable compute Deploy to production with a single click Deploys securely in your cloud account Unlimited compute at no extra cost Secure data integrations Scalable compute backend Highly-available production orchestration Durable metadata Cloud workstations Comprehensive UI Multi-cloud compute Platform- and task-level performance metrics Cost tracking and optimization Auth via SSO and machine tokens Role-Based Access Control Multiple isolated environments Audit logs Fully managed with 24/7 dedicated support\"\n",
      "\n",
      "Instructions: Only reply to the query based on the search results given. Cite each reference using [ Page Number ] notation (every result has this number at the beginning). Weave responses into a coherent and succinct paragraph. Citation should be done in the same words that it refers to in Markdown. Only include information found in the results and Only answer what is asked. The answer should be short and concise. Return a JSON object with the following format: \n",
      "\n",
      "{\n",
      "  \"query\": \"What were major advances in Llama 2?\",\n",
      "  \"answer\": \"Answer here.\"\n",
      "}\n",
      "\n",
      "Answer step-by-step. Include the page number in the most relevant citations. \n",
      "\n",
      "{\n",
      "  \"query\": \"What were major advances in Llama 2?\",\n",
      "  \"answer\":\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Embedding batches: 1\n",
      "[DEBUG] Embedding reshaped: (283, 384)\n",
      "[DEBUG] Fitting Nearest Neighbors model with 6 neighbors.\n",
      "[DEBUG] Fit complete.\n",
      "[DEBUG] Getting nearest neighbors of text: What were major advances in Llama 2?\n",
      "[DEBUG] Embedding: (1, 384)\n"
     ]
    }
   ],
   "source": [
    "text_ls = pdf_to_text(pdf_path)\n",
    "chunks = text_to_chunks(text_ls)\n",
    "recommender.fit([c[0] for c in chunks])\n",
    "\n",
    "question = \"What were major advances in Llama 2?\"\n",
    "topn_chunks = recommender(question)\n",
    "\n",
    "prompt = \"\"\n",
    "prompt += \"search results:\\n\\n\"\n",
    "for c in topn_chunks:\n",
    "    prompt += c + \"\\n\\n\"\n",
    "\n",
    "prompt += (\n",
    "    \"Instructions: Only reply to the query based on the search results given. \"\n",
    "    \"Cite each reference using [ Page Number ] notation \"\n",
    "    \"(every result has this number at the beginning). \"\n",
    "    \"Weave responses into a coherent and succinct paragraph. \"\n",
    "    \"Citation should be done in the same words that it refers to in Markdown. \"\n",
    "    \"Only include information found in the results and \"\n",
    "    \"Only answer what is asked. The answer should be short and concise. \"\n",
    "    \"Return a JSON object with the following format: \\n\\n\"\n",
    "    \"Answer step-by-step. Include the page number in the most relevant citations. \"\n",
    "    \"\\n\\n{\\n\"\n",
    "    f'  \"query\": \"{question}\",\\n'\n",
    "    '  \"answer\":'\n",
    "    \"\\n\"\n",
    ")\n",
    "\n",
    "message_history = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an elite professor specializing in machine learning. \"\n",
    "        + \"Discuss topics related to the search results, and no others.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt,\n",
    "    },\n",
    "]\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\", messages=message_history, response_format={\"type\": \"json_object\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"query\": \"What were major advances in Llama 2?\",\n",
      "  \"answer\": \"Major advances in Llama 2 include the introduction of models with up to 70B parameters, with pretraining methodologies leveraging publicly available online sources, and fine-tuning through supervised methods followed by Reinforcement Learning with Human Feedback (RLHF) methodologies [Page no. 5]. Llama 2-Chat variants, optimized for dialogue use cases, were also released with 7B, 13B, and 70B parameters [Page no. 4]. Evaluation shows Llama 2 70B achieving results close to GPT-3.5 on MMLU and GSM8K benchmarks, and performing on par or better than PaLM (540B) on almost all benchmarks [Page no. 8]. Safety evaluations indicate improvements, with lower toxicity percentages observed in ToxiGen benchmarks and better performance in TruthfulQA benchmarks compared to its predecessors [Page no. 23]. However, the release of the 34B variant was delayed due to insufficient time for comprehensive red-teaming [Page no. 5].\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
