{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eddie/micromamba/envs/pdf-dev/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "try:\n",
    "    import pymupdf as fitz  # available with v1.24.3\n",
    "except ImportError:\n",
    "    import fitz\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from fitz import Document as FitzDocument\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"./pdfs/outerbounds-brief.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(pdf_path)\n",
    "assert doc.is_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 18\n",
      "Metadata: {'author': '',\n",
      " 'creationDate': \"D:20240130113640-08'00'\",\n",
      " 'creator': 'Acrobat Pro 23.8.20470',\n",
      " 'encryption': None,\n",
      " 'format': 'PDF 1.7',\n",
      " 'keywords': '',\n",
      " 'modDate': \"D:20240130113744-08'00'\",\n",
      " 'producer': 'Acrobat Pro 23.8.20470',\n",
      " 'subject': '',\n",
      " 'title': '',\n",
      " 'trapped': ''}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of pages: {doc.page_count}\")\n",
    "print(f\"Metadata: \", end=\"\")\n",
    "pprint(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 'Cover', 1],\n",
      " [1, '1', 2],\n",
      " [1, '2', 3],\n",
      " [1, '3', 4],\n",
      " [1, '4', 5],\n",
      " [1, '5', 6],\n",
      " [1, '6', 7],\n",
      " [1, '7', 8],\n",
      " [1, '8', 9],\n",
      " [1, '9', 10],\n",
      " [1, '10', 11],\n",
      " [1, '11', 12],\n",
      " [1, '12', 13],\n",
      " [1, '13', 14],\n",
      " [1, '14', 15],\n",
      " [1, '15', 16],\n",
      " [1, '16', 17],\n",
      " [1, 'Back', 18]]\n"
     ]
    }
   ],
   "source": [
    "pprint(doc.get_toc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pdf_utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pdf_utils.py\n",
    "try:\n",
    "    import pymupdf as fitz  # available with v1.24.3\n",
    "except ImportError:\n",
    "    import fitz\n",
    "\n",
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def pdf_to_text(path, start_page=1, end_page=None):\n",
    "    doc = fitz.open(path)\n",
    "    total_pages = doc.page_count\n",
    "    if end_page is None:\n",
    "        end_page = total_pages\n",
    "    text_list = []\n",
    "    for i in range(start_page - 1, end_page):\n",
    "        text = doc.load_page(i).get_text(\"text\")\n",
    "        text = preprocess(text)\n",
    "        text_list.append({\"content\": text, \"page\": i + 1})\n",
    "    doc.close()\n",
    "    return text_list\n",
    "\n",
    "\n",
    "def text_to_chunks(texts, word_length=150, start_page=1):\n",
    "    text_toks = [(t[\"content\"].split(\" \"), t[\"page\"]) for t in texts]\n",
    "    chunks = []\n",
    "\n",
    "    for idx, words_and_page in enumerate(text_toks):\n",
    "        words = words_and_page[0]\n",
    "        page = words_and_page[1]\n",
    "        for i in range(0, len(words), word_length):\n",
    "            chunk = words[i : i + word_length]\n",
    "            if (\n",
    "                (i + word_length) > len(words)\n",
    "                and (len(chunk) < word_length)\n",
    "                and (len(text_toks) != (idx + 1))\n",
    "            ):\n",
    "                # text_toks[idx + 1] = chunk + text_toks[idx + 1]\n",
    "                text_toks[idx + 1] = (\n",
    "                    chunk + text_toks[idx + 1][0],\n",
    "                    text_toks[idx + 1][1],\n",
    "                )\n",
    "                continue\n",
    "            chunk = \" \".join(chunk).strip()\n",
    "            chunk = f\"[Page no. {idx+start_page}]\" + \" \" + '\"' + chunk + '\"'\n",
    "            chunks.append((chunk, page))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf_utils import pdf_to_text, text_to_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting semantic_search.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile semantic_search.py\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "TEXT_EMBEDDING_MODEL_INFO = {\n",
    "    \"model_name\": \"all-MiniLM-L6-v2\",\n",
    "    \"model_framework\": \"sentence-transformers\",\n",
    "    \"pretrained_model_provider\": \"Hugging Face\",\n",
    "    \"use_case\": \"text-semantic-search\",\n",
    "}\n",
    "\n",
    "\n",
    "class SemanticSearchModel:\n",
    "    \"\"\"\n",
    "    Manager for a semantic search model.\n",
    "\n",
    "    args:\n",
    "        None\n",
    "\n",
    "    methods:\n",
    "        fit(data: List[str], batch: int, n_neighbors: int) -> None:\n",
    "            Fits the model M with the data.\n",
    "        _get_text_embedding(texts: List[str], batch: int) -> np.ndarray:\n",
    "            Returns the embeddings of the text.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.embedding_model = SentenceTransformer(\n",
    "            TEXT_EMBEDDING_MODEL_INFO[\"model_name\"]\n",
    "        )\n",
    "        self.fitted = False\n",
    "\n",
    "    def _get_text_embedding(self, texts, batch_size=1000):\n",
    "        \"\"\"\n",
    "        Gather a stack of embedded texts, packed batch_size at a time.\n",
    "        \"\"\"\n",
    "        embeddings = []\n",
    "        n_texts = len(texts)\n",
    "        for batch_start_idx in range(0, n_texts, batch_size):\n",
    "            text_batch = texts[batch_start_idx : (batch_start_idx + batch_size)]\n",
    "            embedding_batch = self.embedding_model.encode(text_batch)\n",
    "            embeddings.append(embedding_batch)\n",
    "        print(\"[DEBUG] Embedding batches:\", len(embeddings))\n",
    "        embeddings = np.vstack(embeddings)\n",
    "        print(\"[DEBUG] Embedding reshaped:\", embeddings.shape)\n",
    "        return embeddings\n",
    "\n",
    "    def fit(self, data, batch_size=1000, n_neighbors=6):\n",
    "        \"\"\"\n",
    "        The only public method in this class.\n",
    "        Fits the model with the data when a new PDF is uploaded.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.embeddings = self._get_text_embedding(data, batch_size=batch_size)\n",
    "        n_neighbors = min(n_neighbors, len(self.embeddings))\n",
    "        print(\n",
    "            \"[DEBUG] Fitting Nearest Neighbors model with %s neighbors.\" % n_neighbors\n",
    "        )\n",
    "        self.nn = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "        self.nn.fit(self.embeddings)\n",
    "        print(\"[DEBUG] Fit complete.\")\n",
    "        self.fitted = True\n",
    "\n",
    "    def __call__(self, text, return_data=True):\n",
    "        \"\"\"\n",
    "        Inference time method.\n",
    "        Return the nearest neighbors of a new text.\n",
    "        \"\"\"\n",
    "        print(\"[DEBUG] Getting nearest neighbors of text:\", text)\n",
    "        embedding = self.embedding_model.encode([text])\n",
    "        print(\"[DEBUG] Embedding:\", embedding.shape)\n",
    "        neighbors = self.nn.kneighbors(embedding, return_distance=False)[0]\n",
    "        if return_data:\n",
    "            return [self.data[text_neighbs] for text_neighbs in neighbors]\n",
    "        else:\n",
    "            return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ls = pdf_to_text(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'ML/January 2024 A developer-friendly platform for ML+AI systems ',\n",
       "  'page': 1},\n",
       " {'content': 'Background 1 Outerbounds was spun off from Netflix in 2021. At Netflix, Outerbounds’ founders led ML and AI infrastructure, encoding the best practices of rapid ML/ AI development into an open-source library Metaflow, with a particular focus on human-centric, productivity- boosting developer experience. In addition to powering most ML/AI projects at Netflix today, Metaflow has become an industry-standard tool for production ML/AI systems, adopted by hundreds of leading companies. It powers a wide range of use cases from financial fraud detection and biotech to autonomous drones and custom large language models. Outerbounds builds on the foundation laid by Metaflow by offering it as a part of a fully managed, secure, cost- effective ML and AI platform. ',\n",
       "  'page': 2},\n",
       " {'content': 'Scenario Continuously updating ML with structured data 2 Let’s take a look at a typical business-oriented ML system. The system ingests data from a data warehouse, trains models for classification or forecasting, and uses them to provide up-to-date inferences, integrating results to surrounding systems. Consider common questions that raise during development of a system like this. The challenge is not to ship the above system once, but to develop systems like this routinely, continuously improving results. How to interface data engineering and ML workflows? ML-specific ETL ETL How to allow rapid development of models and features? How to experiment and train models at scale, leveraging the cloud cost-efficiently? How to keep track of all code, data, and models, enabling continuous improvement? Feature Transformations Data exploration Train models Model experiment Batch inference Model registry How to integrate the results into surrounding systems reliably and operate them effortlessly? Production integrations Operations How to deploy all of the above in production in a highly-available manner? Scheduled Execution Monitor Alert How to access data quickly and securely? ',\n",
       "  'page': 3},\n",
       " {'content': 'Based on our experience from working with hundreds of companies, real-world ML and AI systems end up including a these four foundational layers of infrastructure - sometimes organically, sometimes by design: There are many valid technical solutions to each of these layers. While not all approaches are equal, ultimately human factors - the ease of experimentation, development, and operations - tend to dominate the effectiveness of the overall solution. Outerbounds provides a full stack of ML/AI infrastructure, addressing the above layers holistically - take a look how. Accessing data efficiently and securely. Data Leveraging compute resources to process data, train models, and run inference. Compute Orchestrating the system, keeping it running in a highly- available manner. Orchestration Observing and keeping track of code, data, and models across experiments and production. Tracking and Versioning Enabling developers to experiment rapidly, develop effectively, ship to production confidently, and improve results continuously. Developer UX 3 Solution Human-Centric Infrastructure for ML and AI ',\n",
       "  'page': 4},\n",
       " {'content': 'Data 4 Outerbounds integrates to popular data lakes and warehouses which excel at storing and processing structured data. Access data quickly and securely, interface with ETL, process features, and use modern tools for data, while building ML/AI systems cost-efficiently. With a few lines of Python code, you can read data securely from various data sources, following preconfigured paved paths that conform with policies. Workflows can be configured to run automatically whenever new data is available, enabling continuous training and inference. Load both structured and unstructured data at blazing speeds, up to tens of gigabits per second, using a built-in, high-performance data layer. Divide responsibilities clearly between data engineering and ML/AI/data science teams, balancing stability and experimentation. @trigger = ( ): @secrets @snowflake @step start : = .next( .end) \"data_update\" class def self self.x 124 self self (event ) ( ) DataFlow FlowSpec Decoding Parquet from datastore, Gbit/s Small (disk) Medium (disk) Macbook Pro (disk) Medium (tmpfs) Large (tmpfs) Recent runs: Last deployed 7 days ago: 2023-10-18 1:43pm by shri@outerbounds.co Triggered by events: metaflow.PreprocessingFlow Production token: ••••• Show trainingflow Latest run succeeded trainingflow/argo-trainingflow-phn7w Event Trigger: metaflow.PreprocessingFlow Started at: 2023-03-12, 4:40pm Fast data path ETL Project-specific tables/data Authoritative fact tables ML/AI workflow Raw data Project-specific ETL ',\n",
       "  'page': 5}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_ls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_to_chunks(text_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[Page no. 3] \"ML/January 2024 A developer-friendly platform for ML+AI systems  Background 1 Outerbounds was spun off from Netflix in 2021. At Netflix, Outerbounds’ founders led ML and AI infrastructure, encoding the best practices of rapid ML/ AI development into an open-source library Metaflow, with a particular focus on human-centric, productivity- boosting developer experience. In addition to powering most ML/AI projects at Netflix today, Metaflow has become an industry-standard tool for production ML/AI systems, adopted by hundreds of leading companies. It powers a wide range of use cases from financial fraud detection and biotech to autonomous drones and custom large language models. Outerbounds builds on the foundation laid by Metaflow by offering it as a part of a fully managed, secure, cost- effective ML and AI platform.  Scenario Continuously updating ML with structured data 2 Let’s take a look at a typical business-oriented ML system. The system ingests data from a\"',\n",
       "  3),\n",
       " ('[Page no. 3] \"data warehouse, trains models for classification or forecasting, and uses them to provide up-to-date inferences, integrating results to surrounding systems. Consider common questions that raise during development of a system like this. The challenge is not to ship the above system once, but to develop systems like this routinely, continuously improving results. How to interface data engineering and ML workflows? ML-specific ETL ETL How to allow rapid development of models and features? How to experiment and train models at scale, leveraging the cloud cost-efficiently? How to keep track of all code, data, and models, enabling continuous improvement? Feature Transformations Data exploration Train models Model experiment Batch inference Model registry How to integrate the results into surrounding systems reliably and operate them effortlessly? Production integrations Operations How to deploy all of the above in production in a highly-available manner? Scheduled Execution Monitor Alert How to access data quickly and securely?\"',\n",
       "  3),\n",
       " ('[Page no. 4] \"Based on our experience from working with hundreds of companies, real-world ML and AI systems end up including a these four foundational layers of infrastructure - sometimes organically, sometimes by design: There are many valid technical solutions to each of these layers. While not all approaches are equal, ultimately human factors - the ease of experimentation, development, and operations - tend to dominate the effectiveness of the overall solution. Outerbounds provides a full stack of ML/AI infrastructure, addressing the above layers holistically - take a look how. Accessing data efficiently and securely. Data Leveraging compute resources to process data, train models, and run inference. Compute Orchestrating the system, keeping it running in a highly- available manner. Orchestration Observing and keeping track of code, data, and models across experiments and production. Tracking and Versioning Enabling developers to experiment rapidly, develop effectively, ship to production confidently, and improve results continuously. Developer UX\"',\n",
       "  4),\n",
       " ('[Page no. 5] \"3 Solution Human-Centric Infrastructure for ML and AI  Data 4 Outerbounds integrates to popular data lakes and warehouses which excel at storing and processing structured data. Access data quickly and securely, interface with ETL, process features, and use modern tools for data, while building ML/AI systems cost-efficiently. With a few lines of Python code, you can read data securely from various data sources, following preconfigured paved paths that conform with policies. Workflows can be configured to run automatically whenever new data is available, enabling continuous training and inference. Load both structured and unstructured data at blazing speeds, up to tens of gigabits per second, using a built-in, high-performance data layer. Divide responsibilities clearly between data engineering and ML/AI/data science teams, balancing stability and experimentation. @trigger = ( ): @secrets @snowflake @step start : = .next( .end) \"data_update\" class def self self.x 124 self self (event ) ( ) DataFlow\"',\n",
       "  5),\n",
       " ('[Page no. 6] \"FlowSpec Decoding Parquet from datastore, Gbit/s Small (disk) Medium (disk) Macbook Pro (disk) Medium (tmpfs) Large (tmpfs) Recent runs: Last deployed 7 days ago: 2023-10-18 1:43pm by shri@outerbounds.co Triggered by events: metaflow.PreprocessingFlow Production token: ••••• Show trainingflow Latest run succeeded trainingflow/argo-trainingflow-phn7w Event Trigger: metaflow.PreprocessingFlow Started at: 2023-03-12, 4:40pm Fast data path ETL Project-specific tables/data Authoritative fact tables ML/AI workflow Raw data Project-specific ETL  Compute 5 Outerbounds provides a uniquely capable and cost-efficient compute layer. Leverage unlimited compute resources across clouds, covering all instance types, including a wide range of GPUs and other hardware accelerators at the lowest cost for a flat, unmetered fee. Use your existing cloud accounts for compute without extra margin, moving between clouds effortlessly. You can also bring on-prem resources in the mix. Scale your systems up and out in plain Python using your existing code and favorite libraries. No need to learn new paradigms, complex\"',\n",
       "  6),\n",
       " ('[Page no. 7] \"APIs, or limited environments. Train demanding models or fine-tune LLMs with fleets of GPUs with distributed training - Ray, Deepspeed, PyTorch, and MPI are supported out of the box. Compute costs are readily observable in the UI. You can attribute costs down to individual workflows and flows, minimizing costs where it matters. Your Platform Cluster Configuration m5.4xlarge Minimum of 0 nodes / Maximum of 90 nodes Health Min 0 / Max 90 Task details CPU utilization Memory utilization Flows @card = = @gpu_profile = @kubernetes =4 @step generate : utils load_model model = load_model result = . current.card.append(result) .next .end \"blank\", \"gen_ai_results\" ‘Stable Diffusion’ (type id ) (type 1 (gpu ) def (self) from import ( ) self (self ) Flows  Orchestration 6 Outerbounds supports projects from experimentation to production. Compose complex, real- life systems from modular components and deploy them in a highly-available production environment with a single\"',\n",
       "  7),\n",
       " ('[Page no. 8] \"click - or more often, through a CI/CD system. Develop production-ready workflows quickly with open- source Metaflow that has been battle-hardened for years at Netflix and other leading companies. Deploy workflows with a single click and make them run automatically in stable, isolated execution environments, connected to other systems upstream and downstream. Build increasingly advanced systems incrementally by composing larger flows from individual components, dividing responsibilities across teams. Focus on operating your data, models, and applications with full visibility - Outerbounds keeps the foundational infrastructure running. start foreach_account process_account_date branch_step_pages foreach_one_step_page join_foreach_one_step_page branch_node_pages foreach_node_day_page create_history_view Runs Daily data 1 Daily data 2 Daily data 3 + Trigger + Trigger + Trigger Deployments Outerbounds APP 5.20 PM TrainingFlow/argo-3c245e6 succeeded Flow completed in 28m 2s Triggered by FeatureGenerationFlow/argo-eab345 View Flow FeatureGenerationFlow/argo-eab345 succeeded Flow completed in 2h 13m Triggered by data_update/32acb3 View Flow  Versioning & Observability 7 Outerbounds tracks and organizes projects\"',\n",
       "  8),\n",
       " ('[Page no. 8] \"- and models and data they contain - automatically. Build observable ML/AI systems, while drawing secure boundaries between projects, versions, and teams. Metaflow tracks, records, and versions all data, code, and models automatically, providing a built-in model registry and experiment tracker. Access past results with a simple Python API, reuse them in workflows and explore, analyze, and debug them in notebooks or programmatically. Visualize custom metrics and KPIs with real-time dashboards and reports, which are natively integrated in the system through a simple Python API. Deploy and operate any number of system variants, e.g. for A/B testing, knowing that deployments are safely isolated from each other. Tabular data Artifact Name: test_data (55 columns and 441 rows) Runs RealtimeCardFlow/207038 Origin Europe USA Japan from metaflow Flow, namespace namespace Flow .latest_run import ( ) ( ) ‘user:eddie’ ‘MyFlow’ namespace Flow .latest_run ( ) ( ) ‘user:eddie’ ‘MyFlow’ Run(‘MyFlow/11’) . . . Daily\"',\n",
       "  8),\n",
       " ('[Page no. 9] \"data 1  Modeling Deployment Versioning Orchestration Compute Data 8 Boost productivity and happiness with Delightful developer experience Instead of having to navigate disparate tools, Outerbounds offers a single developer-friendly API and a coherent UI covering the full ML and AI stack, so developers with diverse expertise can focus on building and deploying systems rapidly. Gone are the days when AI/ML systems were treated as islands, separate from other production systems. Today’s systems are built on infrastructure and policies which make DevOps, SREs, and other engineers happy too. Outerbounds has increased our appetite for model based solutions. We can use ML in places where we hadn’t considered using it before, now that we know that we can have a reliable model in production quickly. Thanasis Noulas Our goal has been maximizing the utilization of AWS resources and therefore minimizing costs. For us, Outerbounds is a very big efficiency gain, just\"',\n",
       "  9),\n",
       " ('[Page no. 10] \"in terms of efficient utilization of AWS resources. Will High How much infrastructure is needed How much AI/ ML developer cares  from metaflow FlowSpec, step. conda_base,\\\\ kubernetes, schedule @conda_base(libraries={‘ ’: }) @schedule(daily=True) (FlowSpec): @step def start(self): self.x = self.next(self.end) @kubernetes(memory= ) @step def end(self): self.x += print( , self.x) __name__ == : HelloFlow() import scikit-learn class if ’1.1.2’ “Hello world! The value of x is” ‘__main__’ HelloFlow 1 64000 1 Stop writing boilerplate and stitching systems together with YAML, Docker, Python, and clunky cloud APIs. Developed by us at Netflix, open-source Metaflow has set the standard for human-centric, Python-first, ML/AI workflows for years. 9 Making ML/AI developers productive Say bye to mismatching dependencies, underpowered laptops, clunky configurations, and yesterday’s IDEs. Outerbounds workstations are accessible from local VSCode, so you can develop code quickly and conveniently with a modern toolchain, while analyzing data with familiar, managed Jupyter notebooks on the\"',\n",
       "  10),\n",
       " ('[Page no. 12] \"side.  Productive ML/AI developers Debug Develop Deploy Develop locally Create a workflow Scale vertically Access data quickly Package model and libraries Deploy endpoint Explore with notebooks Version everything Scale horizontally Scheduled execution Monitor model 10 Technical debt of ML and AI systems is often blatantly visible, not hidden Best ML/AI systems are designed coherently end-to-end, not stitched together from second-hand parts Metaflow has been a fantastic tool for Carsales. Built with the core idea of allowing ML engineers and data scientists to use Python as a native way to work, this friendly approach has tremendously boosted Carsales\\' productivity in ML related projects. Samuel Than  IAM Policies Audit trail Secrets All access to the platform is authorized through your SSO provider, while security perimeters and role based access control allows you to delineate permissions by team and environment. OB Services Argo Workflows Metaflow Client Outerbounds Control Plane Metadata Service\"',\n",
       "  12),\n",
       " ('[Page no. 13] \"Metaflow UI Auth Service Platform UI Customer Data Node Pools Kubernetes Cluster Metadata Datastore Customer Cloud Account Managed by Outerbounds Outerbounds Cloud Account 11 Built on robust infrastructure With a few clicks, Outerbounds deploys as a fully managed Kubernetes cluster in your AWS, GCP, or Azure account, fenced inside a strict permission boundary. No data or compute ever leaves your premises, so you can integrate ML/AI into your existing systems seamlessly, leveraging existing security policies. Outerbounds manages the cluster 24/7, taking care of upgrades and other maintenance with zero downtime.  Built on robust infrastructure As an administrator, you can configure data access, compute resources, and deployment settings centrally for ML and AI teams. And, you can observe the status of the system conveniently in the same UI. 12 Manage Perimeters Default ville@company.com gaurav@company.com hugo@company.com A Pickle Perimeter ville@company.com brendan@company.com shri@company.com gaurav@company.com 6 Users ville@company.com View brendan@company.com View shri@company.com Execute\"',\n",
       "  13),\n",
       " ('[Page no. 15] \"gaurav@company.com View hugo@company.com Execute jane@company.com View Humans A Pickle Perimeter CPU utilization Memory utilization Flows We are a bank, everything we do needs to be auditable. This means we need to be able to reproduce everything that has been in production. Outerbounds gives us that for free, as all models and metadata are versioned. I sleep much more comfortably knowing this. Thanasis Noulas  outerbounds.com sales@outerbounds.co Get started with free 30 day trial Outerbounds has proven to be transformative for us The ability to scale our operations both vertically and horizontally, and launch parallel experiments and pipelines, has made Metaflow and Outerbounds an appealing choice for our ML team, significantly enhancing our productivity, without the burden of worrying about infra. Soma S Dhavala 13 Develop ML/AI systems, not just models Seamless data integrations Production-grade orchestration Cost-efficient compute at scale Built-in tracking and versioning  12 Appendix Outerbounds vs. Open-Source Metaflow\"',\n",
       "  15),\n",
       " ('[Page no. 15] \"How does the managed Outerbounds platform differ from open-source Metaflow? Outerbounds Developer-friendly API Same open-source Metaflow Yes Yes Yes Yes Basic version in OSS Basic version in OSS Basic version in OSS Basic version in OSS Included Included Included Included Included Included Included Included Included Included Included Included w/ additional features Managed and optimized Managed and optimized Same open-source Metaflow Same open-source Metaflow Same open-source Metaflow Same open-source Metaflow No lock-in, build apps with open-source APIs Version and track everything Simple access to scalable compute Deploy to production with a single click Deploys securely in your cloud account Unlimited compute at no extra cost Secure data integrations Scalable compute backend Highly-available production orchestration Durable metadata Cloud workstations Comprehensive UI Multi-cloud compute Platform- and task-level performance metrics Cost tracking and optimization Auth via SSO and machine tokens Role-Based Access Control Multiple isolated environments Audit logs Fully managed with 24/7 dedicated support\"',\n",
       "  15),\n",
       " ('[Page no. 16] \"Open-source Metwflow  Amazon Sagemaker is a portfolio of over 20 AWS products targeting ML and AI use cases. True to Amazon’s philosophy, these products are built by separate teams in a loosely coupled manner, leaving it to the customer to learn and integrate the parts, some of which are more immature than others, into a working system. Developer Experience Cloud Agnosticity Cost Support Cohesively designed, integrated platform with a particular focus on clean Python APIs and easy operations. Result: Develop and deploy end-to-end systems quicker. The same APIs work across clouds and on- prem. No changes needed to migrate to other clouds. Result: Leverage multiple clouds for cost- optimization and flexibility. Utilize the lowest-cost cloud instances without extra margin. Outerbounds is incentivized to minimize your AWS bill. Result: Lower, transparent, predictable costs, higher ROI. Dedicated Slack channel with experienced engineers, supporting both ML/AI developers and infrastructure. Result: Faster time\"',\n",
       "  16),\n",
       " ('[Page no. 17] \"to market, quicker time to resolution. A portfolio of loosely coupled products with inconsistent APIs and varying levels of maturity. Result: Building and operating systems takes significantly more effort. The APIs are specific to AWS. Complete rewrite needed to migrate to other clouds. Result: Complete lock-in to AWS. Must use ml. instances which are normal EC2 instances with an extra margin. AWS is incentivized to maximize your AWS bill. Result: Higher, opaque, unpredictable costs, lower ROI. Standard AWS support - access to knowledgeable engineers is very expensive. Very limited support for end-user developers. Result: Slower development time, more surprises. Outerbounds Differences Sagemaker 13 Appendix Outerbounds vs. Amazon Sagemaker  Similarities How Amazon Prime Video ships RecSys models 4x faster Amazon uses Metaflow to power recommendations for Prime Video, thanks to its excellent developer experience. Building a GenAI ready ML Platform with Metaflow at Autodesk Autodesk a marquee Sagemaker customer, uses\"',\n",
       "  17),\n",
       " ('[Page no. 17] \"Metaflow with Sagemaker to enable their developers to be productive with demanding Generative AI use cases, and to run large-scale workloads on AWS cost-efficiently. Adopt easily in your AWS account Interoperability Fully Managed Outerbounds deploys in your AWS account through AWS marketplace, becomes a line- item in your AWS invoice. Works seamlessly with other AWS services, authorized via IAM policies. You may leverage any Sagemaker services with Outerbounds. The platform relies on foundational AWS services like EC2 and S3. It is fully managed by Outerbounds 24/7 with a guaranteed SLA. Sagemakers runs in your AWS account, becomes a line-item in your AWS invoice. Works seamlessly with other AWS services, authorized via IAM policies. You must mix-and-match Sagemaker services you want to utilize. The platform relies on foundational AWS services like EC2 and S3. It is fully managed by AWS 24/7 with a guaranteed SLA. Outerbounds Sagemaker 14 Case Studies\"',\n",
       "  17),\n",
       " ('[Page no. 18] \"Smarter machines, built by happier humans outerbounds.com sales@outerbounds.co\"',\n",
       "  18)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[Page no. 3] \"ML/January 2024 A developer-friendly platform for ML+AI systems  Background 1 Outerbounds was spun off from Netflix in 2021. At Netflix, Outerbounds’ founders led ML and AI infrastructure, encoding the best practices of rapid ML/ AI development into an open-source library Metaflow, with a particular focus on human-centric, productivity- boosting developer experience. In addition to powering most ML/AI projects at Netflix today, Metaflow has become an industry-standard tool for production ML/AI systems, adopted by hundreds of leading companies. It powers a wide range of use cases from financial fraud detection and biotech to autonomous drones and custom large language models. Outerbounds builds on the foundation laid by Metaflow by offering it as a part of a fully managed, secure, cost- effective ML and AI platform.  Scenario Continuously updating ML with structured data 2 Let’s take a look at a typical business-oriented ML system. The system ingests data from a\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(chunks[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_search import SemanticSearchModel\n",
    "recommender = SemanticSearchModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Embedding batches: 1\n",
      "[DEBUG] Embedding reshaped: (18, 384)\n",
      "[DEBUG] Fitting Nearest Neighbors model with 6 neighbors.\n",
      "[DEBUG] Fit complete.\n"
     ]
    }
   ],
   "source": [
    "recommender.fit([c[0] for c in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What does Outerbounds do?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Getting nearest neighbors of text: What does Outerbounds do?\n",
      "[DEBUG] Embedding: (1, 384)\n"
     ]
    }
   ],
   "source": [
    "topn_chunks = recommender(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[Page no. 4] \"Based on our experience from working with hundreds of companies, real-world ML and AI systems end up including a these four foundational layers of infrastructure - sometimes organically, sometimes by design: There are many valid technical solutions to each of these layers. While not all approaches are equal, ultimately human factors - the ease of experimentation, development, and operations - tend to dominate the effectiveness of the overall solution. Outerbounds provides a full stack of ML/AI infrastructure, addressing the above layers holistically - take a look how. Accessing data efficiently and securely. Data Leveraging compute resources to process data, train models, and run inference. Compute Orchestrating the system, keeping it running in a highly- available manner. Orchestration Observing and keeping track of code, data, and models across experiments and production. Tracking and Versioning Enabling developers to experiment rapidly, develop effectively, ship to production confidently, and improve results continuously. Developer UX\"',\n",
       " '[Page no. 9] \"data 1  Modeling Deployment Versioning Orchestration Compute Data 8 Boost productivity and happiness with Delightful developer experience Instead of having to navigate disparate tools, Outerbounds offers a single developer-friendly API and a coherent UI covering the full ML and AI stack, so developers with diverse expertise can focus on building and deploying systems rapidly. Gone are the days when AI/ML systems were treated as islands, separate from other production systems. Today’s systems are built on infrastructure and policies which make DevOps, SREs, and other engineers happy too. Outerbounds has increased our appetite for model based solutions. We can use ML in places where we hadn’t considered using it before, now that we know that we can have a reliable model in production quickly. Thanasis Noulas Our goal has been maximizing the utilization of AWS resources and therefore minimizing costs. For us, Outerbounds is a very big efficiency gain, just\"',\n",
       " '[Page no. 3] \"ML/January 2024 A developer-friendly platform for ML+AI systems  Background 1 Outerbounds was spun off from Netflix in 2021. At Netflix, Outerbounds’ founders led ML and AI infrastructure, encoding the best practices of rapid ML/ AI development into an open-source library Metaflow, with a particular focus on human-centric, productivity- boosting developer experience. In addition to powering most ML/AI projects at Netflix today, Metaflow has become an industry-standard tool for production ML/AI systems, adopted by hundreds of leading companies. It powers a wide range of use cases from financial fraud detection and biotech to autonomous drones and custom large language models. Outerbounds builds on the foundation laid by Metaflow by offering it as a part of a fully managed, secure, cost- effective ML and AI platform.  Scenario Continuously updating ML with structured data 2 Let’s take a look at a typical business-oriented ML system. The system ingests data from a\"',\n",
       " '[Page no. 18] \"Smarter machines, built by happier humans outerbounds.com sales@outerbounds.co\"',\n",
       " '[Page no. 15] \"gaurav@company.com View hugo@company.com Execute jane@company.com View Humans A Pickle Perimeter CPU utilization Memory utilization Flows We are a bank, everything we do needs to be auditable. This means we need to be able to reproduce everything that has been in production. Outerbounds gives us that for free, as all models and metadata are versioned. I sleep much more comfortably knowing this. Thanasis Noulas  outerbounds.com sales@outerbounds.co Get started with free 30 day trial Outerbounds has proven to be transformative for us The ability to scale our operations both vertically and horizontally, and launch parallel experiments and pipelines, has made Metaflow and Outerbounds an appealing choice for our ML team, significantly enhancing our productivity, without the burden of worrying about infra. Soma S Dhavala 13 Develop ML/AI systems, not just models Seamless data integrations Production-grade orchestration Cost-efficient compute at scale Built-in tracking and versioning  12 Appendix Outerbounds vs. Open-Source Metaflow\"',\n",
       " '[Page no. 15] \"How does the managed Outerbounds platform differ from open-source Metaflow? Outerbounds Developer-friendly API Same open-source Metaflow Yes Yes Yes Yes Basic version in OSS Basic version in OSS Basic version in OSS Basic version in OSS Included Included Included Included Included Included Included Included Included Included Included Included w/ additional features Managed and optimized Managed and optimized Same open-source Metaflow Same open-source Metaflow Same open-source Metaflow Same open-source Metaflow No lock-in, build apps with open-source APIs Version and track everything Simple access to scalable compute Deploy to production with a single click Deploys securely in your cloud account Unlimited compute at no extra cost Secure data integrations Scalable compute backend Highly-available production orchestration Durable metadata Cloud workstations Comprehensive UI Multi-cloud compute Platform- and task-level performance metrics Cost tracking and optimization Auth via SSO and machine tokens Role-Based Access Control Multiple isolated environments Audit logs Fully managed with 24/7 dedicated support\"']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topn_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[Page no. 15] \"How does the managed Outerbounds platform differ from open-source Metaflow? Outerbounds Developer-friendly API Same open-source Metaflow Yes Yes Yes Yes Basic version in OSS Basic version in OSS Basic version in OSS Basic version in OSS Included Included Included Included Included Included Included Included Included Included Included Included w/ additional features Managed and optimized Managed and optimized Same open-source Metaflow Same open-source Metaflow Same open-source Metaflow Same open-source Metaflow No lock-in, build apps with open-source APIs Version and track everything Simple access to scalable compute Deploy to production with a single click Deploys securely in your cloud account Unlimited compute at no extra cost Secure data integrations Scalable compute backend Highly-available production orchestration Durable metadata Cloud workstations Comprehensive UI Multi-cloud compute Platform- and task-level performance metrics Cost tracking and optimization Auth via SSO and machine tokens Role-Based Access Control Multiple isolated environments Audit logs Fully managed with 24/7 dedicated support\"',\n",
       " 15)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\n",
    "prompt += \"search results:\\n\\n\"\n",
    "for c in topn_chunks:\n",
    "    prompt += c + \"\\n\\n\"\n",
    "\n",
    "# stolen: https://github.com/bhaskatripathi/pdfGPT/blob/main/api.py#L137C5-L146C6\n",
    "prompt += (\n",
    "    \"Instructions: Only reply to the query based on the search results given. \"\n",
    "    \"Cite each reference using [ Page Number ] notation \"\n",
    "    \"(every result has this number at the beginning). \"\n",
    "    \"Weave responses into a coherent and succinct paragraph. \"\n",
    "    \"Citation should be done in the same words that it refers to in Markdown. \"\n",
    "    \"Only include information found in the results and \"\n",
    "    \"Only answer what is asked. The answer should be short and concise. \"\n",
    "    \"Answer step-by-step. Include the page number in the most relevant citations. \"\n",
    "    \"Return a JSON object with the following format: \\n\\n\"\n",
    "    \"\\n\\n{\\n\"\n",
    "    f'  \"query\": \"{question}\",\\n'\n",
    "    '  \"answer\":'\n",
    "    \"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search results:\n",
      "\n",
      "[Page no. 4] \"Based on our experience from working with hundreds of companies, real-world ML and AI systems end up including a these four foundational layers of infrastructure - sometimes organically, sometimes by design: There are many valid technical solutions to each of these layers. While not all approaches are equal, ultimately human factors - the ease of experimentation, development, and operations - tend to dominate the effectiveness of the overall solution. Outerbounds provides a full stack of ML/AI infrastructure, addressing the above layers holistically - take a look how. Accessing data efficiently and securely. Data Leveraging compute resources to process data, train models, and run inference. Compute Orchestrating the system, keeping it running in a highly- available manner. Orchestration Observing and keeping track of code, data, and models across experiments and production. Tracking and Versioning Enabling developers to experiment rapidly, develop effectively, ship to production confidently, and improve results continuously. Developer UX\"\n",
      "\n",
      "[Page no. 9] \"data 1  Modeling Deployment Versioning Orchestration Compute Data 8 Boost productivity and happiness with Delightful developer experience Instead of having to navigate disparate tools, Outerbounds offers a single developer-friendly API and a coherent UI covering the full ML and AI stack, so developers with diverse expertise can focus on building and deploying systems rapidly. Gone are the days when AI/ML systems were treated as islands, separate from other production systems. Today’s systems are built on infrastructure and policies which make DevOps, SREs, and other engineers happy too. Outerbounds has increased our appetite for model based solutions. We can use ML in places where we hadn’t considered using it before, now that we know that we can have a reliable model in production quickly. Thanasis Noulas Our goal has been maximizing the utilization of AWS resources and therefore minimizing costs. For us, Outerbounds is a very big efficiency gain, just\"\n",
      "\n",
      "[Page no. 3] \"ML/January 2024 A developer-friendly platform for ML+AI systems  Background 1 Outerbounds was spun off from Netflix in 2021. At Netflix, Outerbounds’ founders led ML and AI infrastructure, encoding the best practices of rapid ML/ AI development into an open-source library Metaflow, with a particular focus on human-centric, productivity- boosting developer experience. In addition to powering most ML/AI projects at Netflix today, Metaflow has become an industry-standard tool for production ML/AI systems, adopted by hundreds of leading companies. It powers a wide range of use cases from financial fraud detection and biotech to autonomous drones and custom large language models. Outerbounds builds on the foundation laid by Metaflow by offering it as a part of a fully managed, secure, cost- effective ML and AI platform.  Scenario Continuously updating ML with structured data 2 Let’s take a look at a typical business-oriented ML system. The system ingests data from a\"\n",
      "\n",
      "[Page no. 18] \"Smarter machines, built by happier humans outerbounds.com sales@outerbounds.co\"\n",
      "\n",
      "[Page no. 15] \"gaurav@company.com View hugo@company.com Execute jane@company.com View Humans A Pickle Perimeter CPU utilization Memory utilization Flows We are a bank, everything we do needs to be auditable. This means we need to be able to reproduce everything that has been in production. Outerbounds gives us that for free, as all models and metadata are versioned. I sleep much more comfortably knowing this. Thanasis Noulas  outerbounds.com sales@outerbounds.co Get started with free 30 day trial Outerbounds has proven to be transformative for us The ability to scale our operations both vertically and horizontally, and launch parallel experiments and pipelines, has made Metaflow and Outerbounds an appealing choice for our ML team, significantly enhancing our productivity, without the burden of worrying about infra. Soma S Dhavala 13 Develop ML/AI systems, not just models Seamless data integrations Production-grade orchestration Cost-efficient compute at scale Built-in tracking and versioning  12 Appendix Outerbounds vs. Open-Source Metaflow\"\n",
      "\n",
      "[Page no. 15] \"How does the managed Outerbounds platform differ from open-source Metaflow? Outerbounds Developer-friendly API Same open-source Metaflow Yes Yes Yes Yes Basic version in OSS Basic version in OSS Basic version in OSS Basic version in OSS Included Included Included Included Included Included Included Included Included Included Included Included w/ additional features Managed and optimized Managed and optimized Same open-source Metaflow Same open-source Metaflow Same open-source Metaflow Same open-source Metaflow No lock-in, build apps with open-source APIs Version and track everything Simple access to scalable compute Deploy to production with a single click Deploys securely in your cloud account Unlimited compute at no extra cost Secure data integrations Scalable compute backend Highly-available production orchestration Durable metadata Cloud workstations Comprehensive UI Multi-cloud compute Platform- and task-level performance metrics Cost tracking and optimization Auth via SSO and machine tokens Role-Based Access Control Multiple isolated environments Audit logs Fully managed with 24/7 dedicated support\"\n",
      "\n",
      "Instructions: Only reply to the query based on the search results given. Cite each reference using [ Page Number ] notation (every result has this number at the beginning). Weave responses into a coherent and succinct paragraph. Citation should be done in the same words that it refers to in Markdown. Only include information found in the results and Only answer what is asked. The answer should be short and concise. Answer step-by-step. Include the page number in the most relevant citations. Return a JSON object with the following format: \n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "  \"query\": \"What does Outerbounds do?\",\n",
      "  \"answer\":\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an elite professor specializing in machine learning. \"\n",
    "        + \"Discuss topics related to the search results, and no others.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\", \n",
    "    messages=message_history, \n",
    "    response_format={\"type\": \"json_object\"},\n",
    "    max_tokens=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What does Outerbounds do?',\n",
       " 'answer': 'Outerbounds specializes in providing comprehensive ML/AI infrastructure that includes data access, compute resources, orchestration, and tracking/versioning of models and experiments. This infrastructure aims to improve developer productivity and integrates well with existing DevOps practices by offering a developer-friendly API and UI [Page no. 4, Page no. 9]. Originating from Netflix, Outerbounds builds on the open-source library Metaflow and offers it as part of a fully managed platform, enhancing it with additional features like audit logs, multi-cloud compute, and 24/7 dedicated support [Page no. 3, Page no. 15].'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json.loads(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch remote data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "\n",
    "def download(url: str, path: str) -> FitzDocument:\n",
    "    subprocess.run(\n",
    "        [\"wget\", \"--user-agent\", \"Mozilla\", url, \"-O\", path],\n",
    "        stdout=subprocess.DEVNULL,\n",
    "        stderr=subprocess.DEVNULL,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path=\"pdfs/llama2.pdf\"\n",
    "download(\"https://arxiv.org/pdf/2307.09288.pdf\", pdf_path)\n",
    "pdf = fitz.open(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Embedding batches: 1\n",
      "[DEBUG] Embedding reshaped: (283, 384)\n",
      "[DEBUG] Fitting Nearest Neighbors model with 6 neighbors.\n",
      "[DEBUG] Fit complete.\n",
      "[DEBUG] Getting nearest neighbors of text: What were major advances in Llama 2?\n",
      "[DEBUG] Embedding: (1, 384)\n"
     ]
    }
   ],
   "source": [
    "text_ls = pdf_to_text(pdf_path)\n",
    "chunks = text_to_chunks(text_ls)\n",
    "recommender.fit([c[0] for c in chunks])\n",
    "\n",
    "question = \"What were major advances in Llama 2?\"\n",
    "topn_chunks = recommender(question)\n",
    "\n",
    "prompt = \"\"\n",
    "prompt += \"search results:\\n\\n\"\n",
    "for c in topn_chunks:\n",
    "    prompt += c + \"\\n\\n\"\n",
    "\n",
    "prompt += (\n",
    "    \"Instructions: Only reply to the query based on the search results given. \"\n",
    "    \"Cite each reference using [ Page Number ] notation \"\n",
    "    \"(every result has this number at the beginning). \"\n",
    "    \"Weave responses into a coherent and succinct paragraph. \"\n",
    "    \"Citation should be done in the same words that it refers to in Markdown. \"\n",
    "    \"Only include information found in the results and \"\n",
    "    \"Only answer what is asked. The answer should be short and concise. \"\n",
    "    \"Return a JSON object with the following format: \\n\\n\"\n",
    "    \"Answer step-by-step. Include the page number in the most relevant citations. \"\n",
    "    \"\\n\\n{\\n\"\n",
    "    f'  \"query\": \"{question}\",\\n'\n",
    "    '  \"answer\":'\n",
    "    \"\\n\"\n",
    ")\n",
    "\n",
    "message_history = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an elite professor specializing in machine learning. \"\n",
    "        + \"Discuss topics related to the search results, and no others.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt,\n",
    "    },\n",
    "]\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\", messages=message_history, response_format={\"type\": \"json_object\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"query\": \"What were major advances in Llama 2?\",\n",
      "  \"answer\": \"Major advances in Llama 2 include the release of models with 7B, 13B, and 70B parameters, alongside reports on but not the release of a 34B variant [Page no. 4]. The fine-tuning of Llama 2 has been optimized for dialogue use cases, resulting in Llama 2-Chat, which employs Reinforcement Learning with Human Feedback methodologies for iterative refinement [Page no. 5]. Llama 2 70B has shown performance close to GPT-3.5 on MMLU and GSM8K benchmarks and on par or better than PaLM on almost all benchmarks, although there remains a gap with GPT-4 and PaLM-2-L [Page no. 8]. Moreover, Llama 2's benchmarks on models like MMLU and BBH showed improvements of approximately 5 and 8 points, respectively, over Llama 1 65B, highlighting a significant performance enhancement [Page no. 8]. Testing has been primarily conducted in English, and extensive safety evaluations and tuning are recommended to ensure appropriate use [Page no. 4, Page no. 77].\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
