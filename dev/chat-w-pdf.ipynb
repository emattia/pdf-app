{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    import pymupdf as fitz  # available with v1.24.3\n",
    "except ImportError:\n",
    "    import fitz\n",
    "\n",
    "from fitz import Document as FitzDocument\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from openai import OpenAI\n",
    "from IPython.display import display, Markdown, JSON\n",
    "\n",
    "from pprint import pprint\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "import re\n",
    "import os\n",
    "\n",
    "# from llama_index.readers.file import PyMuPDFReader\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp ../backend/data/*.pdf ./pdfs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path=\"./pdfs/Outerbounds-ML-Jan30-Reduced.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(pdf_path)\n",
    "assert doc.is_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 18\n",
      "Metadata: {'author': '',\n",
      " 'creationDate': \"D:20240130113640-08'00'\",\n",
      " 'creator': 'Acrobat Pro 23.8.20470',\n",
      " 'encryption': None,\n",
      " 'format': 'PDF 1.7',\n",
      " 'keywords': '',\n",
      " 'modDate': \"D:20240130113744-08'00'\",\n",
      " 'producer': 'Acrobat Pro 23.8.20470',\n",
      " 'subject': '',\n",
      " 'title': '',\n",
      " 'trapped': ''}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of pages: {doc.page_count}\")\n",
    "print(f\"Metadata: \", end='')\n",
    "pprint(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 'Cover', 1],\n",
      " [1, '1', 2],\n",
      " [1, '2', 3],\n",
      " [1, '3', 4],\n",
      " [1, '4', 5],\n",
      " [1, '5', 6],\n",
      " [1, '6', 7],\n",
      " [1, '7', 8],\n",
      " [1, '8', 9],\n",
      " [1, '9', 10],\n",
      " [1, '10', 11],\n",
      " [1, '11', 12],\n",
      " [1, '12', 13],\n",
      " [1, '13', 14],\n",
      " [1, '14', 15],\n",
      " [1, '15', 16],\n",
      " [1, '16', 17],\n",
      " [1, 'Back', 18]]\n"
     ]
    }
   ],
   "source": [
    "pprint(doc.get_toc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def pdf_to_text(\n",
    "    path,\n",
    "    start_page=1, \n",
    "    end_page=None\n",
    "):\n",
    "    doc = fitz.open(path)\n",
    "    total_pages = doc.page_count\n",
    "    if end_page is None:\n",
    "        end_page = total_pages\n",
    "    text_list = []\n",
    "    for i in range(start_page - 1, end_page):\n",
    "        text = doc.load_page(i).get_text(\"text\")\n",
    "        text = preprocess(text)\n",
    "        text_list.append({'content': text, 'page': i + 1})\n",
    "    doc.close()\n",
    "    return text_list\n",
    "\n",
    "\n",
    "def text_to_chunks(\n",
    "    texts, \n",
    "    word_length=150, \n",
    "    start_page=1\n",
    "):\n",
    "    text_toks = [\n",
    "        (t['content'].split(' '), t['page'])\n",
    "        for t in texts\n",
    "    ]\n",
    "    chunks = []\n",
    "\n",
    "    for idx, words_and_page in enumerate(text_toks):\n",
    "        words = words_and_page[0]\n",
    "        page = words_and_page[1]\n",
    "        for i in range(0, len(words), word_length):\n",
    "            chunk = words[i : i + word_length]\n",
    "            if (\n",
    "                (i + word_length) > len(words)\n",
    "                and (len(chunk) < word_length)\n",
    "                and (len(text_toks) != (idx + 1))\n",
    "            ):\n",
    "                # text_toks[idx + 1] = chunk + text_toks[idx + 1]\n",
    "                text_toks[idx + 1] = (\n",
    "                    chunk + text_toks[idx + 1][0],\n",
    "                    text_toks[idx + 1][1],\n",
    "                )\n",
    "                continue\n",
    "            chunk = ' '.join(chunk).strip()\n",
    "            chunk = f'[Page no. {idx+start_page}]' + ' ' + '\"' + chunk + '\"'\n",
    "            chunks.append((chunk, page))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/bhaskatripathi/pdfGPT/blob/main/api.py#L105\n",
    "class SemanticSearch:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.use = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, data, batch=1000, n_neighbors=5):\n",
    "        self.data = data\n",
    "        self.embeddings = self.get_text_embedding(data, batch=batch)\n",
    "        n_neighbors = min(n_neighbors, len(self.embeddings))\n",
    "        self.nn = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "        self.nn.fit(self.embeddings)\n",
    "        self.fitted = True\n",
    "\n",
    "    def __call__(self, text, return_data=True):\n",
    "        inp_emb = self.use([text])\n",
    "        neighbors = self.nn.kneighbors(inp_emb, return_distance=False)[0]\n",
    "\n",
    "        if return_data:\n",
    "            return [self.data[i] for i in neighbors]\n",
    "        else:\n",
    "            return neighbors\n",
    "\n",
    "    def get_text_embedding(self, texts, batch=1000):\n",
    "        embeddings = []\n",
    "        for i in range(0, len(texts), batch):\n",
    "            text_batch = texts[i : (i + batch)]\n",
    "            emb_batch = self.use(text_batch)\n",
    "            embeddings.append(emb_batch)\n",
    "        embeddings = np.vstack(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ls = pdf_to_text(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'ML/January 2024 A developer-friendly platform for ML+AI systems ',\n",
       "  'page': 1},\n",
       " {'content': 'Background 1 Outerbounds was spun off from Netflix in 2021. At Netflix, Outerbounds’ founders led ML and AI infrastructure, encoding the best practices of rapid ML/ AI development into an open-source library Metaflow, with a particular focus on human-centric, productivity- boosting developer experience. In addition to powering most ML/AI projects at Netflix today, Metaflow has become an industry-standard tool for production ML/AI systems, adopted by hundreds of leading companies. It powers a wide range of use cases from financial fraud detection and biotech to autonomous drones and custom large language models. Outerbounds builds on the foundation laid by Metaflow by offering it as a part of a fully managed, secure, cost- effective ML and AI platform. ',\n",
       "  'page': 2},\n",
       " {'content': 'Scenario Continuously updating ML with structured data 2 Let’s take a look at a typical business-oriented ML system. The system ingests data from a data warehouse, trains models for classification or forecasting, and uses them to provide up-to-date inferences, integrating results to surrounding systems. Consider common questions that raise during development of a system like this. The challenge is not to ship the above system once, but to develop systems like this routinely, continuously improving results. How to interface data engineering and ML workflows? ML-specific ETL ETL How to allow rapid development of models and features? How to experiment and train models at scale, leveraging the cloud cost-efficiently? How to keep track of all code, data, and models, enabling continuous improvement? Feature Transformations Data exploration Train models Model experiment Batch inference Model registry How to integrate the results into surrounding systems reliably and operate them effortlessly? Production integrations Operations How to deploy all of the above in production in a highly-available manner? Scheduled Execution Monitor Alert How to access data quickly and securely? ',\n",
       "  'page': 3},\n",
       " {'content': 'Based on our experience from working with hundreds of companies, real-world ML and AI systems end up including a these four foundational layers of infrastructure - sometimes organically, sometimes by design: There are many valid technical solutions to each of these layers. While not all approaches are equal, ultimately human factors - the ease of experimentation, development, and operations - tend to dominate the effectiveness of the overall solution. Outerbounds provides a full stack of ML/AI infrastructure, addressing the above layers holistically - take a look how. Accessing data efficiently and securely. Data Leveraging compute resources to process data, train models, and run inference. Compute Orchestrating the system, keeping it running in a highly- available manner. Orchestration Observing and keeping track of code, data, and models across experiments and production. Tracking and Versioning Enabling developers to experiment rapidly, develop effectively, ship to production confidently, and improve results continuously. Developer UX 3 Solution Human-Centric Infrastructure for ML and AI ',\n",
       "  'page': 4},\n",
       " {'content': 'Data 4 Outerbounds integrates to popular data lakes and warehouses which excel at storing and processing structured data. Access data quickly and securely, interface with ETL, process features, and use modern tools for data, while building ML/AI systems cost-efficiently. With a few lines of Python code, you can read data securely from various data sources, following preconfigured paved paths that conform with policies. Workflows can be configured to run automatically whenever new data is available, enabling continuous training and inference. Load both structured and unstructured data at blazing speeds, up to tens of gigabits per second, using a built-in, high-performance data layer. Divide responsibilities clearly between data engineering and ML/AI/data science teams, balancing stability and experimentation. @trigger = ( ): @secrets @snowflake @step start : = .next( .end) \"data_update\" class def self self.x 124 self self (event ) ( ) DataFlow FlowSpec Decoding Parquet from datastore, Gbit/s Small (disk) Medium (disk) Macbook Pro (disk) Medium (tmpfs) Large (tmpfs) Recent runs: Last deployed 7 days ago: 2023-10-18 1:43pm by shri@outerbounds.co Triggered by events: metaflow.PreprocessingFlow Production token: ••••• Show trainingflow Latest run succeeded trainingflow/argo-trainingflow-phn7w Event Trigger: metaflow.PreprocessingFlow Started at: 2023-03-12, 4:40pm Fast data path ETL Project-specific tables/data Authoritative fact tables ML/AI workflow Raw data Project-specific ETL ',\n",
       "  'page': 5}]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_ls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_to_chunks(text_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[Page no. 3] \"ML/January 2024 A developer-friendly platform for ML+AI systems  Background 1 Outerbounds was spun off from Netflix in 2021. At Netflix, Outerbounds’ founders led ML and AI infrastructure, encoding the best practices of rapid ML/ AI development into an open-source library Metaflow, with a particular focus on human-centric, productivity- boosting developer experience. In addition to powering most ML/AI projects at Netflix today, Metaflow has become an industry-standard tool for production ML/AI systems, adopted by hundreds of leading companies. It powers a wide range of use cases from financial fraud detection and biotech to autonomous drones and custom large language models. Outerbounds builds on the foundation laid by Metaflow by offering it as a part of a fully managed, secure, cost- effective ML and AI platform.  Scenario Continuously updating ML with structured data 2 Let’s take a look at a typical business-oriented ML system. The system ingests data from a\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(chunks[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = SemanticSearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender.fit([c[0] for c in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'What does Outerbounds do?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn_chunks = recommender(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[Page no. 8] \"click - or more often, through a CI/CD system. Develop production-ready workflows quickly with open- source Metaflow that has been battle-hardened for years at Netflix and other leading companies. Deploy workflows with a single click and make them run automatically in stable, isolated execution environments, connected to other systems upstream and downstream. Build increasingly advanced systems incrementally by composing larger flows from individual components, dividing responsibilities across teams. Focus on operating your data, models, and applications with full visibility - Outerbounds keeps the foundational infrastructure running. start foreach_account process_account_date branch_step_pages foreach_one_step_page join_foreach_one_step_page branch_node_pages foreach_node_day_page create_history_view Runs Daily data 1 Daily data 2 Daily data 3 + Trigger + Trigger + Trigger Deployments Outerbounds APP 5.20 PM TrainingFlow/argo-3c245e6 succeeded Flow completed in 28m 2s Triggered by FeatureGenerationFlow/argo-eab345 View Flow FeatureGenerationFlow/argo-eab345 succeeded Flow completed in 2h 13m Triggered by data_update/32acb3 View Flow  Versioning & Observability 7 Outerbounds tracks and organizes projects\"',\n",
       " '[Page no. 18] \"Smarter machines, built by happier humans outerbounds.com sales@outerbounds.co\"',\n",
       " '[Page no. 8] \"- and models and data they contain - automatically. Build observable ML/AI systems, while drawing secure boundaries between projects, versions, and teams. Metaflow tracks, records, and versions all data, code, and models automatically, providing a built-in model registry and experiment tracker. Access past results with a simple Python API, reuse them in workflows and explore, analyze, and debug them in notebooks or programmatically. Visualize custom metrics and KPIs with real-time dashboards and reports, which are natively integrated in the system through a simple Python API. Deploy and operate any number of system variants, e.g. for A/B testing, knowing that deployments are safely isolated from each other. Tabular data Artifact Name: test_data (55 columns and 441 rows) Runs RealtimeCardFlow/207038 Origin Europe USA Japan from metaflow Flow, namespace namespace Flow .latest_run import ( ) ( ) ‘user:eddie’ ‘MyFlow’ namespace Flow .latest_run ( ) ( ) ‘user:eddie’ ‘MyFlow’ Run(‘MyFlow/11’) . . . Daily\"',\n",
       " '[Page no. 3] \"ML/January 2024 A developer-friendly platform for ML+AI systems  Background 1 Outerbounds was spun off from Netflix in 2021. At Netflix, Outerbounds’ founders led ML and AI infrastructure, encoding the best practices of rapid ML/ AI development into an open-source library Metaflow, with a particular focus on human-centric, productivity- boosting developer experience. In addition to powering most ML/AI projects at Netflix today, Metaflow has become an industry-standard tool for production ML/AI systems, adopted by hundreds of leading companies. It powers a wide range of use cases from financial fraud detection and biotech to autonomous drones and custom large language models. Outerbounds builds on the foundation laid by Metaflow by offering it as a part of a fully managed, secure, cost- effective ML and AI platform.  Scenario Continuously updating ML with structured data 2 Let’s take a look at a typical business-oriented ML system. The system ingests data from a\"',\n",
       " '[Page no. 15] \"How does the managed Outerbounds platform differ from open-source Metaflow? Outerbounds Developer-friendly API Same open-source Metaflow Yes Yes Yes Yes Basic version in OSS Basic version in OSS Basic version in OSS Basic version in OSS Included Included Included Included Included Included Included Included Included Included Included Included w/ additional features Managed and optimized Managed and optimized Same open-source Metaflow Same open-source Metaflow Same open-source Metaflow Same open-source Metaflow No lock-in, build apps with open-source APIs Version and track everything Simple access to scalable compute Deploy to production with a single click Deploys securely in your cloud account Unlimited compute at no extra cost Secure data integrations Scalable compute backend Highly-available production orchestration Durable metadata Cloud workstations Comprehensive UI Multi-cloud compute Platform- and task-level performance metrics Cost tracking and optimization Auth via SSO and machine tokens Role-Based Access Control Multiple isolated environments Audit logs Fully managed with 24/7 dedicated support\"']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topn_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[Page no. 15] \"How does the managed Outerbounds platform differ from open-source Metaflow? Outerbounds Developer-friendly API Same open-source Metaflow Yes Yes Yes Yes Basic version in OSS Basic version in OSS Basic version in OSS Basic version in OSS Included Included Included Included Included Included Included Included Included Included Included Included w/ additional features Managed and optimized Managed and optimized Same open-source Metaflow Same open-source Metaflow Same open-source Metaflow Same open-source Metaflow No lock-in, build apps with open-source APIs Version and track everything Simple access to scalable compute Deploy to production with a single click Deploys securely in your cloud account Unlimited compute at no extra cost Secure data integrations Scalable compute backend Highly-available production orchestration Durable metadata Cloud workstations Comprehensive UI Multi-cloud compute Platform- and task-level performance metrics Cost tracking and optimization Auth via SSO and machine tokens Role-Based Access Control Multiple isolated environments Audit logs Fully managed with 24/7 dedicated support\"',\n",
       " 15)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\n",
    "prompt += 'search results:\\n\\n'\n",
    "for c in topn_chunks:\n",
    "    prompt += c + '\\n\\n'\n",
    "\n",
    "# stolen: https://github.com/bhaskatripathi/pdfGPT/blob/main/api.py#L137C5-L146C6\n",
    "prompt += (\n",
    "    \"Instructions: Only reply to the query based on the search results given. \"\n",
    "    \"Cite each reference using [ Page Number ] notation \"\n",
    "    \"(every result has this number at the beginning). \"\n",
    "    \"Weave responses into a coherent and succinct paragraph. \"\n",
    "    \"Citation should be done in the same words that it refers to in Markdown. \"\n",
    "    \"Only include information found in the results and \"\n",
    "    \"Only answer what is asked. The answer should be short and concise. \"\n",
    "    \"Return a JSON object with the following format: \\n\\n\"\n",
    "    \n",
    "    \"{\\n\"\n",
    "    f'  \"query\": \"{question}\",\\n'\n",
    "    '  \"answer\": \"Answer here.\"\\n'\n",
    "    \"}\\n\\n\"\n",
    "\n",
    "    \"Answer step-by-step. Include the page number in the most relevant citations. \"\n",
    "\n",
    "    \"\\n\\n{\\n\"\n",
    "    f'  \"query\": \"{question}\",\\n'\n",
    "    '  \"answer\":'\n",
    "    \"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search results:\n",
      "\n",
      "[Page no. 8] \"click - or more often, through a CI/CD system. Develop production-ready workflows quickly with open- source Metaflow that has been battle-hardened for years at Netflix and other leading companies. Deploy workflows with a single click and make them run automatically in stable, isolated execution environments, connected to other systems upstream and downstream. Build increasingly advanced systems incrementally by composing larger flows from individual components, dividing responsibilities across teams. Focus on operating your data, models, and applications with full visibility - Outerbounds keeps the foundational infrastructure running. start foreach_account process_account_date branch_step_pages foreach_one_step_page join_foreach_one_step_page branch_node_pages foreach_node_day_page create_history_view Runs Daily data 1 Daily data 2 Daily data 3 + Trigger + Trigger + Trigger Deployments Outerbounds APP 5.20 PM TrainingFlow/argo-3c245e6 succeeded Flow completed in 28m 2s Triggered by FeatureGenerationFlow/argo-eab345 View Flow FeatureGenerationFlow/argo-eab345 succeeded Flow completed in 2h 13m Triggered by data_update/32acb3 View Flow  Versioning & Observability 7 Outerbounds tracks and organizes projects\"\n",
      "\n",
      "[Page no. 18] \"Smarter machines, built by happier humans outerbounds.com sales@outerbounds.co\"\n",
      "\n",
      "[Page no. 8] \"- and models and data they contain - automatically. Build observable ML/AI systems, while drawing secure boundaries between projects, versions, and teams. Metaflow tracks, records, and versions all data, code, and models automatically, providing a built-in model registry and experiment tracker. Access past results with a simple Python API, reuse them in workflows and explore, analyze, and debug them in notebooks or programmatically. Visualize custom metrics and KPIs with real-time dashboards and reports, which are natively integrated in the system through a simple Python API. Deploy and operate any number of system variants, e.g. for A/B testing, knowing that deployments are safely isolated from each other. Tabular data Artifact Name: test_data (55 columns and 441 rows) Runs RealtimeCardFlow/207038 Origin Europe USA Japan from metaflow Flow, namespace namespace Flow .latest_run import ( ) ( ) ‘user:eddie’ ‘MyFlow’ namespace Flow .latest_run ( ) ( ) ‘user:eddie’ ‘MyFlow’ Run(‘MyFlow/11’) . . . Daily\"\n",
      "\n",
      "[Page no. 3] \"ML/January 2024 A developer-friendly platform for ML+AI systems  Background 1 Outerbounds was spun off from Netflix in 2021. At Netflix, Outerbounds’ founders led ML and AI infrastructure, encoding the best practices of rapid ML/ AI development into an open-source library Metaflow, with a particular focus on human-centric, productivity- boosting developer experience. In addition to powering most ML/AI projects at Netflix today, Metaflow has become an industry-standard tool for production ML/AI systems, adopted by hundreds of leading companies. It powers a wide range of use cases from financial fraud detection and biotech to autonomous drones and custom large language models. Outerbounds builds on the foundation laid by Metaflow by offering it as a part of a fully managed, secure, cost- effective ML and AI platform.  Scenario Continuously updating ML with structured data 2 Let’s take a look at a typical business-oriented ML system. The system ingests data from a\"\n",
      "\n",
      "[Page no. 15] \"How does the managed Outerbounds platform differ from open-source Metaflow? Outerbounds Developer-friendly API Same open-source Metaflow Yes Yes Yes Yes Basic version in OSS Basic version in OSS Basic version in OSS Basic version in OSS Included Included Included Included Included Included Included Included Included Included Included Included w/ additional features Managed and optimized Managed and optimized Same open-source Metaflow Same open-source Metaflow Same open-source Metaflow Same open-source Metaflow No lock-in, build apps with open-source APIs Version and track everything Simple access to scalable compute Deploy to production with a single click Deploys securely in your cloud account Unlimited compute at no extra cost Secure data integrations Scalable compute backend Highly-available production orchestration Durable metadata Cloud workstations Comprehensive UI Multi-cloud compute Platform- and task-level performance metrics Cost tracking and optimization Auth via SSO and machine tokens Role-Based Access Control Multiple isolated environments Audit logs Fully managed with 24/7 dedicated support\"\n",
      "\n",
      "Instructions: Only reply to the query based on the search results given. Cite each reference using [ Page Number ] notation (every result has this number at the beginning). Weave responses into a coherent and succinct paragraph. Citation should be done in the same words that it refers to in Markdown. Only include information found in the results and Only answer what is asked. The answer should be short and concise. Return a JSON object with the following format: \n",
      "\n",
      "{\n",
      "  \"query\": \"What does Outerbounds do?\",\n",
      "  \"answer\": \"Answer here.\"\n",
      "}\n",
      "\n",
      "Answer step-by-step. Include the page number in the most relevant citations. \n",
      "\n",
      "{\n",
      "  \"query\": \"What does Outerbounds do?\",\n",
      "  \"answer\":\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an elite professor specializing in machine learning. \" + \\\n",
    "                   \"Discuss topics related to the search results, and no others.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=message_history,\n",
    "    response_format={ \"type\": \"json_object\" }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What does Outerbounds do?',\n",
       " 'answer': 'Outerbounds provides a developer-friendly platform for ML and AI systems, spun off from Netflix in 2021. It builds on the open-source library Metaflow, which is designed for rapid development and a human-centric developer experience. Outerbounds offers a fully managed, secure, and cost-effective ML and AI platform that includes features like scalable compute, secure data integrations, and highly-available production orchestration. The platform tracks, records, and versions all data, code, and models automatically, and it allows for easy deployment and operation of system variants for tasks like A/B testing. Additionally, it provides tools for visualizing custom metrics and KPIs with real-time dashboards and reports [Page no. 3, Page no. 8, Page no. 15].'}"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.loads(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch remote data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"pdfs/llama2.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "def download_and_open(url: str, path: str) -> FitzDocument:\n",
    "    # !wget --user-agent \"Mozilla\" \"{url}\" -O \"{path}\"\n",
    "    subprocess.run([\"wget\", \"--user-agent\", \"Mozilla\", url, \"-O\", path])\n",
    "    return fitz.open(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "--2024-06-29 12:02:53--  https://arxiv.org/pdf/2307.09288.pdf\n",
      "Resolving arxiv.org (arxiv.org)... 151.101.131.42, 151.101.3.42, 151.101.195.42, ...\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.131.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://arxiv.org/pdf/2307.09288 [following]\n",
      "--2024-06-29 12:02:53--  http://arxiv.org/pdf/2307.09288\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.131.42|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13661300 (13M) [application/pdf]\n",
      "Saving to: ‘pdfs/llama2.pdf’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0% 3.56M 4s\n",
      "    50K .......... .......... .......... .......... ..........  0% 28.5M 2s\n",
      "   100K .......... .......... .......... .......... ..........  1% 4.95M 2s\n",
      "   150K .......... .......... .......... .......... ..........  1% 13.6M 2s\n",
      "   200K .......... .......... .......... .......... ..........  1% 27.7M 2s\n",
      "   250K .......... .......... .......... .......... ..........  2% 7.89M 2s\n",
      "   300K .......... .......... .......... .......... ..........  2% 47.4M 1s\n",
      "   350K .......... .......... .......... .......... ..........  2% 22.4M 1s\n",
      "   400K .......... .......... .......... .......... ..........  3% 72.1M 1s\n",
      "   450K .......... .......... .......... .......... ..........  3% 36.1M 1s\n",
      "   500K .......... .......... .......... .......... ..........  4% 17.7M 1s\n",
      "   550K .......... .......... .......... .......... ..........  4% 17.2M 1s\n",
      "   600K .......... .......... .......... .......... ..........  4% 47.7M 1s\n",
      "   650K .......... .......... .......... .......... ..........  5% 55.4M 1s\n",
      "   700K .......... .......... .......... .......... ..........  5% 83.9M 1s\n",
      "   750K .......... .......... .......... .......... ..........  5% 22.9M 1s\n",
      "   800K .......... .......... .......... .......... ..........  6%  105M 1s\n",
      "   850K .......... .......... .......... .......... ..........  6% 45.8M 1s\n",
      "   900K .......... .......... .......... .......... ..........  7% 28.7M 1s\n",
      "   950K .......... .......... .......... .......... ..........  7% 40.2M 1s\n",
      "  1000K .......... .......... .......... .......... ..........  7% 1000K 1s\n",
      "  1050K .......... .......... .......... .......... ..........  8% 37.7M 1s\n",
      "  1100K .......... .......... .......... .......... ..........  8% 76.5M 1s\n",
      "  1150K .......... .......... .......... .......... ..........  8% 59.7M 1s\n",
      "  1200K .......... .......... .......... .......... ..........  9% 53.1M 1s\n",
      "  1250K .......... .......... .......... .......... ..........  9% 59.8M 1s\n",
      "  1300K .......... .......... .......... .......... .......... 10% 23.0M 1s\n",
      "  1350K .......... .......... .......... .......... .......... 10%  407M 1s\n",
      "  1400K .......... .......... .......... .......... .......... 10%  319M 1s\n",
      "  1450K .......... .......... .......... .......... .......... 11% 44.6M 1s\n",
      "  1500K .......... .......... .......... .......... .......... 11% 96.3M 0s\n",
      "  1550K .......... .......... .......... .......... .......... 11% 65.0M 0s\n",
      "  1600K .......... .......... .......... .......... .......... 12%  111M 0s\n",
      "  1650K .......... .......... .......... .......... .......... 12% 74.8M 0s\n",
      "  1700K .......... .......... .......... .......... .......... 13%  154M 0s\n",
      "  1750K .......... .......... .......... .......... .......... 13% 28.4M 0s\n",
      "  1800K .......... .......... .......... .......... .......... 13% 78.3M 0s\n",
      "  1850K .......... .......... .......... .......... .......... 14% 69.8M 0s\n",
      "  1900K .......... .......... .......... .......... .......... 14%  191M 0s\n",
      "  1950K .......... .......... .......... .......... .......... 14% 95.0M 0s\n",
      "  2000K .......... .......... .......... .......... .......... 15% 37.4M 0s\n",
      "  2050K .......... .......... .......... .......... .......... 15%  341M 0s\n",
      "  2100K .......... .......... .......... .......... .......... 16% 56.9M 0s\n",
      "  2150K .......... .......... .......... .......... .......... 16%  243M 0s\n",
      "  2200K .......... .......... .......... .......... .......... 16% 73.5M 0s\n",
      "  2250K .......... .......... .......... .......... .......... 17%  196M 0s\n",
      "  2300K .......... .......... .......... .......... .......... 17% 37.6M 0s\n",
      "  2350K .......... .......... .......... .......... .......... 17% 1000K 0s\n",
      "  2400K .......... .......... .......... .......... .......... 18% 56.0M 0s\n",
      "  2450K .......... .......... .......... .......... .......... 18%  141M 0s\n",
      "  2500K .......... .......... .......... .......... .......... 19% 86.0M 0s\n",
      "  2550K .......... .......... .......... .......... .......... 19% 57.4M 0s\n",
      "  2600K .......... .......... .......... .......... .......... 19% 67.8M 0s\n",
      "  2650K .......... .......... .......... .......... .......... 20% 81.7M 0s\n",
      "  2700K .......... .......... .......... .......... .......... 20%  117M 0s\n",
      "  2750K .......... .......... .......... .......... .......... 20% 58.1M 0s\n",
      "  2800K .......... .......... .......... .......... .......... 21%  561M 0s\n",
      "  2850K .......... .......... .......... .......... .......... 21% 69.7M 0s\n",
      "  2900K .......... .......... .......... .......... .......... 22%  147M 0s\n",
      "  2950K .......... .......... .......... .......... .......... 22% 49.5M 0s\n",
      "  3000K .......... .......... .......... .......... .......... 22%  479M 0s\n",
      "  3050K .......... .......... .......... .......... .......... 23% 58.5M 0s\n",
      "  3100K .......... .......... .......... .......... .......... 23% 1000K 0s\n",
      "  3150K .......... .......... .......... .......... .......... 23% 35.2M 0s\n",
      "  3200K .......... .......... .......... .......... .......... 24% 1000K 0s\n",
      "  3250K .......... .......... .......... .......... .......... 24% 8.97M 0s\n",
      "  3300K .......... .......... .......... .......... .......... 25%  238M 0s\n",
      "  3350K .......... .......... .......... .......... .......... 25%  603M 0s\n",
      "  3400K .......... .......... .......... .......... .......... 25%  474M 0s\n",
      "  3450K .......... .......... .......... .......... .......... 26% 1000K 0s\n",
      "  3500K .......... .......... .......... .......... .......... 26%  404M 0s\n",
      "  3550K .......... .......... .......... .......... .......... 26%  440M 0s\n",
      "  3600K .......... .......... .......... .......... .......... 27%  364M 0s\n",
      "  3650K .......... .......... .......... .......... .......... 27% 39.8M 0s\n",
      "  3700K .......... .......... .......... .......... .......... 28%  751M 0s\n",
      "  3750K .......... .......... .......... .......... .......... 28% 80.4M 0s\n",
      "  3800K .......... .......... .......... .......... .......... 28% 59.3M 0s\n",
      "  3850K .......... .......... .......... .......... .......... 29%  268M 0s\n",
      "  3900K .......... .......... .......... .......... .......... 29% 43.1M 0s\n",
      "  3950K .......... .......... .......... .......... .......... 29%  305M 0s\n",
      "  4000K .......... .......... .......... .......... .......... 30%  274M 0s\n",
      "  4050K .......... .......... .......... .......... .......... 30% 37.7M 0s\n",
      "  4100K .......... .......... .......... .......... .......... 31%  179M 0s\n",
      "  4150K .......... .......... .......... .......... .......... 31% 81.9M 0s\n",
      "  4200K .......... .......... .......... .......... .......... 31% 91.1M 0s\n",
      "  4250K .......... .......... .......... .......... .......... 32% 1000K 0s\n",
      "  4300K .......... .......... .......... .......... .......... 32%  101M 0s\n",
      "  4350K .......... .......... .......... .......... .......... 32% 64.7M 0s\n",
      "  4400K .......... .......... .......... .......... .......... 33%  112M 0s\n",
      "  4450K .......... .......... .......... .......... .......... 33% 95.7M 0s\n",
      "  4500K .......... .......... .......... .......... .......... 34% 88.8M 0s\n",
      "  4550K .......... .......... .......... .......... .......... 34% 40.5M 0s\n",
      "  4600K .......... .......... .......... .......... .......... 34% 1000K 0s\n",
      "  4650K .......... .......... .......... .......... .......... 35% 48.1M 0s\n",
      "  4700K .......... .......... .......... .......... .......... 35%  417M 0s\n",
      "  4750K .......... .......... .......... .......... .......... 35%  364M 0s\n",
      "  4800K .......... .......... .......... .......... .......... 36%  148M 0s\n",
      "  4850K .......... .......... .......... .......... .......... 36% 56.5M 0s\n",
      "  4900K .......... .......... .......... .......... .......... 37%  323M 0s\n",
      "  4950K .......... .......... .......... .......... .......... 37% 28.3M 0s\n",
      "  5000K .......... .......... .......... .......... .......... 37%  135M 0s\n",
      "  5050K .......... .......... .......... .......... .......... 38% 94.4M 0s\n",
      "  5100K .......... .......... .......... .......... .......... 38%  102M 0s\n",
      "  5150K .......... .......... .......... .......... .......... 38% 41.5M 0s\n",
      "  5200K .......... .......... .......... .......... .......... 39%  525M 0s\n",
      "  5250K .......... .......... .......... .......... .......... 39%  125M 0s\n",
      "  5300K .......... .......... .......... .......... .......... 40%  105M 0s\n",
      "  5350K .......... .......... .......... .......... .......... 40% 84.5M 0s\n",
      "  5400K .......... .......... .......... .......... .......... 40% 1000K 0s\n",
      "  5450K .......... .......... .......... .......... .......... 41% 54.7M 0s\n",
      "  5500K .......... .......... .......... .......... .......... 41%  161M 0s\n",
      "  5550K .......... .......... .......... .......... .......... 41% 22.5M 0s\n",
      "  5600K .......... .......... .......... .......... .......... 42% 59.4M 0s\n",
      "  5650K .......... .......... .......... .......... .......... 42%  111M 0s\n",
      "  5700K .......... .......... .......... .......... .......... 43%  379M 0s\n",
      "  5750K .......... .......... .......... .......... .......... 43% 48.2M 0s\n",
      "  5800K .......... .......... .......... .......... .......... 43%  143M 0s\n",
      "  5850K .......... .......... .......... .......... .......... 44% 49.1M 0s\n",
      "  5900K .......... .......... .......... .......... .......... 44%  452M 0s\n",
      "  5950K .......... .......... .......... .......... .......... 44%  111M 0s\n",
      "  6000K .......... .......... .......... .......... .......... 45% 1000K 0s\n",
      "  6050K .......... .......... .......... .......... .......... 45% 98.6M 0s\n",
      "  6100K .......... .......... .......... .......... .......... 46%  100M 0s\n",
      "  6150K .......... .......... .......... .......... .......... 46%  105M 0s\n",
      "  6200K .......... .......... .......... .......... .......... 46% 39.6M 0s\n",
      "  6250K .......... .......... .......... .......... .......... 47%  381M 0s\n",
      "  6300K .......... .......... .......... .......... .......... 47%  108M 0s\n",
      "  6350K .......... .......... .......... .......... .......... 47%  296M 0s\n",
      "  6400K .......... .......... .......... .......... .......... 48% 27.5M 0s\n",
      "  6450K .......... .......... .......... .......... .......... 48%  150M 0s\n",
      "  6500K .......... .......... .......... .......... .......... 49%  132M 0s\n",
      "  6550K .......... .......... .......... .......... .......... 49% 37.1M 0s\n",
      "  6600K .......... .......... .......... .......... .......... 49%  346M 0s\n",
      "  6650K .......... .......... .......... .......... .......... 50%  110M 0s\n",
      "  6700K .......... .......... .......... .......... .......... 50%  114M 0s\n",
      "  6750K .......... .......... .......... .......... .......... 50% 44.2M 0s\n",
      "  6800K .......... .......... .......... .......... .......... 51%  436M 0s\n",
      "  6850K .......... .......... .......... .......... .......... 51%  117M 0s\n",
      "  6900K .......... .......... .......... .......... .......... 52% 1000K 0s\n",
      "  6950K .......... .......... .......... .......... .......... 52% 52.2M 0s\n",
      "  7000K .......... .......... .......... .......... .......... 52% 1000K 0s\n",
      "  7050K .......... .......... .......... .......... .......... 53% 51.1M 0s\n",
      "  7100K .......... .......... .......... .......... .......... 53% 1000K 0s\n",
      "  7150K .......... .......... .......... .......... .......... 53% 95.7M 0s\n",
      "  7200K .......... .......... .......... .......... .......... 54% 85.5M 0s\n",
      "  7250K .......... .......... .......... .......... .......... 54% 79.9M 0s\n",
      "  7300K .......... .......... .......... .......... .......... 55%  104M 0s\n",
      "  7350K .......... .......... .......... .......... .......... 55% 93.0M 0s\n",
      "  7400K .......... .......... .......... .......... .......... 55% 86.4M 0s\n",
      "  7450K .......... .......... .......... .......... .......... 56% 34.5M 0s\n",
      "  7500K .......... .......... .......... .......... .......... 56%  404M 0s\n",
      "  7550K .......... .......... .......... .......... .......... 56% 1000K 0s\n",
      "  7600K .......... .......... .......... .......... .......... 57%  153M 0s\n",
      "  7650K .......... .......... .......... .......... .......... 57%  105M 0s\n",
      "  7700K .......... .......... .......... .......... .......... 58% 81.7M 0s\n",
      "  7750K .......... .......... .......... .......... .......... 58% 55.4M 0s\n",
      "  7800K .......... .......... .......... .......... .......... 58% 86.4M 0s\n",
      "  7850K .......... .......... .......... .......... .......... 59% 98.2M 0s\n",
      "  7900K .......... .......... .......... .......... .......... 59% 1000K 0s\n",
      "  7950K .......... .......... .......... .......... .......... 59% 39.5M 0s\n",
      "  8000K .......... .......... .......... .......... .......... 60%  610M 0s\n",
      "  8050K .......... .......... .......... .......... .......... 60% 56.6M 0s\n",
      "  8100K .......... .......... .......... .......... .......... 61%  634M 0s\n",
      "  8150K .......... .......... .......... .......... .......... 61%  133M 0s\n",
      "  8200K .......... .......... .......... .......... .......... 61% 62.7M 0s\n",
      "  8250K .......... .......... .......... .......... .......... 62% 50.9M 0s\n",
      "  8300K .......... .......... .......... .......... .......... 62%  660M 0s\n",
      "  8350K .......... .......... .......... .......... .......... 62%  479M 0s\n",
      "  8400K .......... .......... .......... .......... .......... 63% 26.5M 0s\n",
      "  8450K .......... .......... .......... .......... .......... 63%  561M 0s\n",
      "  8500K .......... .......... .......... .......... .......... 64% 1000K 0s\n",
      "  8550K .......... .......... .......... .......... .......... 64%  138M 0s\n",
      "  8600K .......... .......... .......... .......... .......... 64% 65.8M 0s\n",
      "  8650K .......... .......... .......... .......... .......... 65%  603M 0s\n",
      "  8700K .......... .......... .......... .......... .......... 65% 69.2M 0s\n",
      "  8750K .......... .......... .......... .......... .......... 65% 45.2M 0s\n",
      "  8800K .......... .......... .......... .......... .......... 66% 1000K 0s\n",
      "  8850K .......... .......... .......... .......... .......... 66% 69.4M 0s\n",
      "  8900K .......... .......... .......... .......... .......... 67% 1000K 0s\n",
      "  8950K .......... .......... .......... .......... .......... 67% 52.9M 0s\n",
      "  9000K .......... .......... .......... .......... .......... 67%  456M 0s\n",
      "  9050K .......... .......... .......... .......... .......... 68% 35.7M 0s\n",
      "  9100K .......... .......... .......... .......... .......... 68% 1000K 0s\n",
      "  9150K .......... .......... .......... .......... .......... 68% 70.0M 0s\n",
      "  9200K .......... .......... .......... .......... .......... 69%  123M 0s\n",
      "  9250K .......... .......... .......... .......... .......... 69% 60.8M 0s\n",
      "  9300K .......... .......... .......... .......... .......... 70%  112M 0s\n",
      "  9350K .......... .......... .......... .......... .......... 70%  103M 0s\n",
      "  9400K .......... .......... .......... .......... .......... 70% 39.4M 0s\n",
      "  9450K .......... .......... .......... .......... .......... 71%  394M 0s\n",
      "  9500K .......... .......... .......... .......... .......... 71% 1000K 0s\n",
      "  9550K .......... .......... .......... .......... .......... 71% 10.4M 0s\n",
      "  9600K .......... .......... .......... .......... .......... 72% 1000K 0s\n",
      "  9650K .......... .......... .......... .......... .......... 72%  503M 0s\n",
      "  9700K .......... .......... .......... .......... .......... 73%  503M 0s\n",
      "  9750K .......... .......... .......... .......... .......... 73%  581M 0s\n",
      "  9800K .......... .......... .......... .......... .......... 73%  465M 0s\n",
      "  9850K .......... .......... .......... .......... .......... 74% 1000K 0s\n",
      "  9900K .......... .......... .......... .......... .......... 74% 26.6M 0s\n",
      "  9950K .......... .......... .......... .......... .......... 74%  105M 0s\n",
      " 10000K .......... .......... .......... .......... .......... 75% 40.0M 0s\n",
      " 10050K .......... .......... .......... .......... .......... 75%  214M 0s\n",
      " 10100K .......... .......... .......... .......... .......... 76% 37.2M 0s\n",
      " 10150K .......... .......... .......... .......... .......... 76%  162M 0s\n",
      " 10200K .......... .......... .......... .......... .......... 76% 65.9M 0s\n",
      " 10250K .......... .......... .......... .......... .......... 77%  230M 0s\n",
      " 10300K .......... .......... .......... .......... .......... 77% 62.7M 0s\n",
      " 10350K .......... .......... .......... .......... .......... 77%  105M 0s\n",
      " 10400K .......... .......... .......... .......... .......... 78% 57.7M 0s\n",
      " 10450K .......... .......... .......... .......... .......... 78%  139M 0s\n",
      " 10500K .......... .......... .......... .......... .......... 79% 61.0M 0s\n",
      " 10550K .......... .......... .......... .......... .......... 79% 72.8M 0s\n",
      " 10600K .......... .......... .......... .......... .......... 79% 49.7M 0s\n",
      " 10650K .......... .......... .......... .......... .......... 80%  313M 0s\n",
      " 10700K .......... .......... .......... .......... .......... 80%  243M 0s\n",
      " 10750K .......... .......... .......... .......... .......... 80% 18.3M 0s\n",
      " 10800K .......... .......... .......... .......... .......... 81%  483M 0s\n",
      " 10850K .......... .......... .......... .......... .......... 81%  514M 0s\n",
      " 10900K .......... .......... .......... .......... .......... 82% 1000K 0s\n",
      " 10950K .......... .......... .......... .......... .......... 82%  140M 0s\n",
      " 11000K .......... .......... .......... .......... .......... 82% 87.2M 0s\n",
      " 11050K .......... .......... .......... .......... .......... 83% 31.1M 0s\n",
      " 11100K .......... .......... .......... .......... .......... 83% 1000K 0s\n",
      " 11150K .......... .......... .......... .......... .......... 83%  223M 0s\n",
      " 11200K .......... .......... .......... .......... .......... 84% 56.4M 0s\n",
      " 11250K .......... .......... .......... .......... .......... 84% 1000K 0s\n",
      " 11300K .......... .......... .......... .......... .......... 85% 72.7M 0s\n",
      " 11350K .......... .......... .......... .......... .......... 85%  105M 0s\n",
      " 11400K .......... .......... .......... .......... .......... 85%  116M 0s\n",
      " 11450K .......... .......... .......... .......... .......... 86% 97.5M 0s\n",
      " 11500K .......... .......... .......... .......... .......... 86% 90.9M 0s\n",
      " 11550K .......... .......... .......... .......... .......... 86% 52.4M 0s\n",
      " 11600K .......... .......... .......... .......... .......... 87%  718M 0s\n",
      " 11650K .......... .......... .......... .......... .......... 87% 69.9M 0s\n",
      " 11700K .......... .......... .......... .......... .......... 88% 1000K 0s\n",
      " 11750K .......... .......... .......... .......... .......... 88% 40.7M 0s\n",
      " 11800K .......... .......... .......... .......... .......... 88%  678M 0s\n",
      " 11850K .......... .......... .......... .......... .......... 89%  159M 0s\n",
      " 11900K .......... .......... .......... .......... .......... 89% 40.9M 0s\n",
      " 11950K .......... .......... .......... .......... .......... 89% 1000K 0s\n",
      " 12000K .......... .......... .......... .......... .......... 90%  112M 0s\n",
      " 12050K .......... .......... .......... .......... .......... 90% 62.4M 0s\n",
      " 12100K .......... .......... .......... .......... .......... 91% 37.1M 0s\n",
      " 12150K .......... .......... .......... .......... .......... 91% 1000K 0s\n",
      " 12200K .......... .......... .......... .......... .......... 91% 39.2M 0s\n",
      " 12250K .......... .......... .......... .......... .......... 92%  519M 0s\n",
      " 12300K .......... .......... .......... .......... .......... 92%  282M 0s\n",
      " 12350K .......... .......... .......... .......... .......... 92% 80.3M 0s\n",
      " 12400K .......... .......... .......... .......... .......... 93% 87.0M 0s\n",
      " 12450K .......... .......... .......... .......... .......... 93% 70.8M 0s\n",
      " 12500K .......... .......... .......... .......... .......... 94% 65.4M 0s\n",
      " 12550K .......... .......... .......... .......... .......... 94%  148M 0s\n",
      " 12600K .......... .......... .......... .......... .......... 94% 58.4M 0s\n",
      " 12650K .......... .......... .......... .......... .......... 95%  112M 0s\n",
      " 12700K .......... .......... .......... .......... .......... 95% 54.7M 0s\n",
      " 12750K .......... .......... .......... .......... .......... 95%  519M 0s\n",
      " 12800K .......... .......... .......... .......... .......... 96%  119M 0s\n",
      " 12850K .......... .......... .......... .......... .......... 96% 43.8M 0s\n",
      " 12900K .......... .......... .......... .......... .......... 97%  651M 0s\n",
      " 12950K .......... .......... .......... .......... .......... 97%  124M 0s\n",
      " 13000K .......... .......... .......... .......... .......... 97% 1000K 0s\n",
      " 13050K .......... .......... .......... .......... .......... 98% 42.9M 0s\n",
      " 13100K .......... .......... .......... .......... .......... 98%  113M 0s\n",
      " 13150K .......... .......... .......... .......... .......... 98% 1000K 0s\n",
      " 13200K .......... .......... .......... .......... .......... 99%  110M 0s\n",
      " 13250K .......... .......... .......... .......... .......... 99% 39.1M 0s\n",
      " 13300K .......... .......... .......... .......... .         100% 73.9M=0.2s\n",
      "\n",
      "2024-06-29 12:02:54 (65.0 MB/s) - ‘pdfs/llama2.pdf’ saved [13661300/13661300]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = download_and_open(\"https://arxiv.org/pdf/2307.09288.pdf\", \"pdfs/llama2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pymupdf.Document"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_parser = SentenceSplitter(\n",
    "    chunk_size=1024,\n",
    "    # separator=\" \",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = []; doc_idxs = []\n",
    "for doc_idx, doc in enumerate(documents):\n",
    "    cur_text_chunks = text_parser.split_text(doc.text)\n",
    "    text_chunks.extend(cur_text_chunks)\n",
    "    doc_idxs.extend([doc_idx] * len(cur_text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "nodes = []\n",
    "for idx, text_chunk in enumerate(text_chunks):\n",
    "    node = TextNode(text=text_chunk)\n",
    "    src_doc = documents[doc_idxs[idx]]\n",
    "    node.metadata = src_doc.metadata\n",
    "    nodes.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in nodes:\n",
    "    node_embedding = embed_model.get_text_embedding(\n",
    "        node.get_content(metadata_mode=\"all\")\n",
    "    )\n",
    "    node.embedding = node_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load nodes into vector stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6b9759b1-d9f7-497f-aaca-5d2ab7caf131',\n",
       " 'a627933b-4163-42e2-ac37-fcd2456e08da',\n",
       " '43831fa7-8e73-43b3-b3df-6ca8188d8e11',\n",
       " '2d884c06-af36-4766-b607-79d8f268a273',\n",
       " 'a3766d1a-1a20-45b8-96e5-d5151a0a196e',\n",
       " '7c3f3309-8284-4a9c-ab8b-1f63e2f174b0',\n",
       " '1210d171-7b44-4071-92d4-399f2f4262b3',\n",
       " '19bdd5e9-58f2-4499-9c78-27263bb62129',\n",
       " '5e22e169-37f2-4135-8136-0df46326852e',\n",
       " '09c78565-3901-4fe1-8688-238837eafc70',\n",
       " '53eb5d2a-6200-402b-8908-5280320eb720',\n",
       " 'f9195249-88b0-4c3a-bab8-9f43158e0424',\n",
       " 'e8905a70-ab74-4d49-9c90-9018753cbb65',\n",
       " '3000b8e6-9944-48ba-a28c-aed145ce6434',\n",
       " '80b8b29a-caad-43d4-bf48-b38654e53209',\n",
       " 'ec60da24-79f8-40d6-a176-44a12498ee4c',\n",
       " 'bf62e53c-949a-453f-8866-d974c942f97e',\n",
       " 'cb76a6c5-b6ea-4e27-8c4d-8b83de257d39',\n",
       " '225ac8dc-190d-431d-a7f1-3fead2ac5d76',\n",
       " '5fbf5fdf-8a88-482f-b0fd-4ef792370eb8',\n",
       " 'befcf16a-388d-42a0-9bda-f0214ccbf36f',\n",
       " '089d9dfa-eb6d-4c9f-9991-4cedb5fa096c',\n",
       " '83fb5f0a-4d29-4ce3-8ca8-e4b09c2fa637',\n",
       " 'ec375fa3-5796-40e6-97b8-be0164944d90',\n",
       " 'ae88c8f2-140c-4557-a0a8-932f9427c047',\n",
       " '7e7fa5aa-b71f-4230-940a-6fc71c057062',\n",
       " '37942e14-19ca-4417-8e99-eef5d609a5b1',\n",
       " '5373bf52-d5f8-402c-a2d4-3b09cb6128fc',\n",
       " '231867ad-7aba-4bd2-9843-856f934b52e9',\n",
       " 'badecd69-82ba-45fa-ac9a-f923e1e3f0cb',\n",
       " 'd4f98308-038a-4a18-a573-231cf182ed2f',\n",
       " '6f3cc4b6-ab87-4740-8047-13a8b866ba3a',\n",
       " 'e3098ba3-2320-48f5-9d88-2bc359be7237',\n",
       " '11154cc2-80fb-4191-a06c-216a59af0131',\n",
       " '7a305a57-693f-41d4-ac3c-5ccf88076243',\n",
       " '00914c50-206d-42e8-a0ab-cda0d89cfe09',\n",
       " 'cbdcf045-4acc-4b9c-98d1-8a09be15cb8c',\n",
       " '5d56d72f-ccf8-4256-ad11-5a15fde4632d',\n",
       " 'eaadb758-6353-43e0-98b2-05c82464aebc',\n",
       " '183c0d56-3aef-4362-84b2-804fa1d24252',\n",
       " '6cc69ccb-77b5-40c5-9dc9-6db415e12e65',\n",
       " '17a36a72-bbac-428c-9091-9759544c609b',\n",
       " 'aab19e84-f45f-469a-8a3c-58342ffaa0e7',\n",
       " 'd7e791f2-0f6a-436b-ae5a-55c7f8e80a5f',\n",
       " '3e11844e-1e6b-48d2-ad6e-673c88c3f481',\n",
       " 'b60109c8-3f8c-442d-8ae5-08a75164d87b',\n",
       " 'f3eac172-855c-4dff-9bb9-71accd88ad7e',\n",
       " 'f8d09c77-4072-49e8-98be-aad2efd87c91',\n",
       " 'dafc36c8-1a14-45cd-b41f-22e927823a06',\n",
       " '7e245cc2-e729-4714-a560-9fa9bb16ba47',\n",
       " 'aaff9710-bcbd-47f3-aa04-296e7ddef1c5',\n",
       " 'd04581d4-da60-417f-8763-0ac2d45ad565',\n",
       " '8f7d5274-0046-46e4-a6d3-f7ac432f9447',\n",
       " 'd2938395-d791-4e8c-a575-244f5e49a382',\n",
       " '88a73b90-bc67-4151-af01-583811ade0a0',\n",
       " '695549c2-1132-447b-93df-a2ef6166a44c',\n",
       " 'c5a7d398-1de0-4601-be54-d2064c80ddd9',\n",
       " '0061ae94-b7df-45f7-a80e-e3ce47238fcf',\n",
       " '6c126ce3-db7b-498f-9ffa-05d174e06743',\n",
       " 'b848cf5c-ee3b-4c0b-a607-35c02aa4402a',\n",
       " '315eb8d5-d2a8-4847-a04c-8a4716855c55',\n",
       " '72b85c65-ec62-483f-a704-0d49fbfd0164',\n",
       " '75e75a7d-dd20-4afb-b365-c4d26e524acd',\n",
       " 'a9cfc5ad-aa3f-439f-aaf0-77efd073ae18',\n",
       " 'fb08740c-7ea5-45cd-bd75-bbf7aa4559c9',\n",
       " '1d0835bb-f0d9-4c9d-a058-7dd2600dca07',\n",
       " '13bdb88e-44e2-4881-a4bc-15f6dd7e321e',\n",
       " 'baf63f1f-b5a3-4cce-b3ce-751d0c74a356',\n",
       " 'd8f22223-9787-44c6-b500-fbe0ee9e3dca',\n",
       " 'b72e74a4-38aa-4693-8da6-81d417d1b3b2',\n",
       " 'c3fef3d7-2ec4-4c24-897b-012826ba7e3a',\n",
       " '386a2ea7-24d8-47ea-80b1-c7df0cb1b29c',\n",
       " '53ac9da5-4597-40e4-83a1-c363490100b6',\n",
       " 'd2df76ba-ff7d-4e9a-8790-753250a0696a',\n",
       " '6d3bb67d-137f-4312-b41e-0de16f1491e3',\n",
       " 'b37d78d2-04f3-404e-b116-f8616949066b',\n",
       " '0329f350-8375-42ff-b558-270023ebbf8d',\n",
       " '052a70b8-fa9b-43d1-90a0-bb3b2ba06548',\n",
       " 'b5af39f1-5db4-4318-af9f-9f85c61a72c4',\n",
       " 'b9ca0950-c4d7-4c87-af43-cc60e4716cc7',\n",
       " '801a4726-2391-49b4-9049-19be161ea9a8',\n",
       " '73d6b921-6366-4861-97ad-2ea525355123',\n",
       " '66232f0a-e7b5-415c-990f-164e75da73c2',\n",
       " '550b2cc3-e86a-4d51-b1a1-858dcd81a274',\n",
       " '85921f67-538d-4800-b226-fa748b1f5aba',\n",
       " '4f0987ea-d66b-42a9-9f0d-c3535fd82e82',\n",
       " '60be2b97-4349-4b66-a56b-b512859b3bb1',\n",
       " '1e68d0f1-b4f1-470d-8dba-cc5bb7809554',\n",
       " 'f0138407-453d-49a7-af81-a665b9242ab4',\n",
       " 'cb3ef91d-b429-4225-b2bb-846cfcf04945',\n",
       " '0ad25422-b6f6-4621-9dac-e40f11049579',\n",
       " 'f60aa06c-6e09-410b-b7da-b8d462b74f57',\n",
       " '3e886183-ba60-499c-8f79-ff878f1fad09',\n",
       " '037a4a6e-fa86-4572-a1f9-b97fab6ceb6c',\n",
       " 'fd8c19bc-09d5-4901-8dce-45a05fddebfc',\n",
       " 'c32ed1b8-0da5-4e5e-aad9-0490238385cd',\n",
       " 'a877ba33-925b-463c-a7f1-cf2549a0e11f',\n",
       " '474f3c21-dd15-45bc-904e-a7e532ef50d9',\n",
       " '4a9c12ef-eaf9-40e8-9733-77fa9c7e44e4',\n",
       " '16202375-625a-48f3-a9a4-5e59ef4ceadb',\n",
       " '93daf5ee-9851-4a14-800f-734e263fec7b',\n",
       " 'b5f3b708-9c00-4b66-9bcc-8485c428e2f2',\n",
       " '85ba329f-bd38-4b40-abbe-3297ed83c1aa',\n",
       " '363bf78a-d92a-4323-b197-b61561fb923f',\n",
       " 'f9f3913b-b340-4d89-90f3-d0ff8fc666f7',\n",
       " 'b3e7dd11-7a87-4340-8bc3-93adc1a250e9',\n",
       " 'bf57d601-ad90-4dff-b5b3-bb2d77de6823']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.vector_stores.duckdb import DuckDBVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "vector_store = DuckDBVectorStore()\n",
    "vector_store.add(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"Can you tell me about the key concepts for safety finetuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = embed_model.get_query_embedding(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import VectorStoreQuery\n",
    "query_mode = \"default\"\n",
    "vector_store_query = VectorStoreQuery(\n",
    "    query_embedding=query_embedding, similarity_top_k=2, mode=query_mode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = vector_store.query(vector_store_query)\n",
    "# print(query_result.nodes[0].get_content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import NodeWithScore\n",
    "from typing import Optional\n",
    "\n",
    "nodes_with_scores = []\n",
    "for index, node in enumerate(query_result.nodes):\n",
    "    score: Optional[float] = None\n",
    "    if query_result.similarities is not None:\n",
    "        score = query_result.similarities[index]\n",
    "    nodes_with_scores.append(NodeWithScore(node=node, score=score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='6f3cc4b6-ab87-4740-8047-13a8b866ba3a', embedding=None, metadata={'total_pages': 77, 'file_path': 'pdfs/llama2.pdf', 'source': '23'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='TruthfulQA ↑\\nToxiGen ↓\\nMPT\\n7B\\n29.13\\n22.32\\n30B\\n35.25\\n22.61\\nFalcon\\n7B\\n25.95\\n14.53\\n40B\\n40.39\\n23.44\\nLlama 1\\n7B\\n27.42\\n23.00\\n13B\\n41.74\\n23.08\\n33B\\n44.19\\n22.57\\n65B\\n48.71\\n21.77\\nLlama 2\\n7B\\n33.29\\n21.25\\n13B\\n41.86\\n26.10\\n34B\\n43.45\\n21.19\\n70B\\n50.18\\n24.60\\nTable 11: Evaluation of pretrained LLMs on automatic safety benchmarks. For TruthfulQA, we present the\\npercentage of generations that are both truthful and informative (the higher the better). For ToxiGen, we\\npresent the percentage of toxic generations (the smaller, the better).\\nBenchmarks give a summary view of model capabilities and behaviors that allow us to understand general\\npatterns in the model, but they do not provide a fully comprehensive view of the impact the model may have\\non people or real-world outcomes; that would require study of end-to-end product deployments. Further\\ntesting and mitigation should be done to understand bias and other social issues for the specific context\\nin which a system may be deployed. For this, it may be necessary to test beyond the groups available in\\nthe BOLD dataset (race, religion, and gender). As LLMs are integrated and deployed, we look forward to\\ncontinuing research that will amplify their potential for positive impact on these important social issues.\\n4.2\\nSafety Fine-Tuning\\nIn this section, we describe our approach to safety fine-tuning, including safety categories, annotation\\nguidelines, and the techniques we use to mitigate safety risks. We employ a process similar to the general\\nfine-tuning methods as described in Section 3, with some notable differences related to safety concerns.\\nSpecifically, we use the following techniques in safety fine-tuning:\\n1. Supervised Safety Fine-Tuning: We initialize by gathering adversarial prompts and safe demonstra-\\ntions that are then included in the general supervised fine-tuning process (Section 3.1). This teaches\\nthe model to align with our safety guidelines even before RLHF, and thus lays the foundation for\\nhigh-quality human preference data annotation.\\n2. Safety RLHF: Subsequently, we integrate safety in the general RLHF pipeline described in Sec-\\ntion 3.2.2. This includes training a safety-specific reward model and gathering more challenging\\nadversarial prompts for rejection sampling style fine-tuning and PPO optimization.\\n3. Safety Context Distillation: Finally, we refine our RLHF pipeline with context distillation (Askell\\net al., 2021b). This involves generating safer model responses by prefixing a prompt with a safety\\npreprompt, e.g., “You are a safe and responsible assistant,” and then fine-tuning the model on the safer\\nresponses without the preprompt, which essentially distills the safety preprompt (context) into the\\nmodel. We use a targeted approach that allows our safety reward model to choose whether to use\\ncontext distillation for each sample.\\n4.2.1\\nSafety Categories and Annotation Guidelines\\nBased on limitations of LLMs known from prior work, we design instructions for our annotation team to\\ncreate adversarial prompts along two dimensions: a risk category, or potential topic about which the LLM\\ncould produce unsafe content; and an attack vector, or question style to cover different varieties of prompts\\nthat could elicit bad model behaviors.\\nThe risk categories considered can be broadly divided into the following three categories: illicit and criminal\\nactivities (e.g., terrorism, theft, human trafficking); hateful and harmful activities (e.g., defamation, self-\\nharm, eating disorders, discrimination); and unqualified advice (e.g., medical advice, financial advice, legal\\n23', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8595475927371214),\n",
       " NodeWithScore(node=TextNode(id_='1e68d0f1-b4f1-470d-8dba-cc5bb7809554', embedding=None, metadata={'total_pages': 77, 'file_path': 'pdfs/llama2.pdf', 'source': '64'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='0.0\\n0.2\\n0.4\\n0.6\\n0.8\\n1.0\\nSafety RM Score\\n0.0\\n0.2\\n0.4\\n0.6\\n0.8\\n1.0\\nHelpfulness RM Score\\nSafe Responses\\n0.0\\n0.2\\n0.4\\n0.6\\n0.8\\n1.0\\nSafety RM Score\\n0.0\\n0.2\\n0.4\\n0.6\\n0.8\\n1.0\\nHelpfulness RM Score\\nUnsafe Responses\\nFigure 32: Safety and Helpfulness reward model scores on a set of safe (left) and unsafe (right) responses\\nfrom the safety test set. The safe or unsafe labels are provided by annotators during preference annotation.\\nConflicts can be observed between the two aspects at the bottom right corner (i.e., high safety score but low\\nhelpfulness score) of the safe response plot and the top left corner (i.e., low safety score but high helpfulness\\nscore) of the unsafe response plot.\\nYou are an responsible and safe assistant that never gives an answer that is in any way insensitive, sexist,\\nracist, or socially inappropriate. When in doubt, it’s better to point out what is problematic with the human’s\\nquestion rather than saying “I don’t know”.\\nThe following user question has been flagged as unsafe. Please respond in a way that is safe and positive.\\nYou are an friendly and responsible assistant assistant. Please refrain from giving any legally questionable or\\ndangerous advice in your responses. Please ensure that your responses are socially unbiased and positive in\\nnature.\\nThe following is a discussion between a human and a knowledgeable and empathetic assistant. The assis-\\ntant’s answers should not include any harmful, unethical, or socially biased content, and should move the\\nconversation in a positive direction.\\n(Based on a specific risk category) The following is a question that can elicit unsafe behavior from you. The\\nquestion was classified as belonging to the violating category: ‘Criminal / Fraudulent Content’. You should\\nanswer using the following template:\\n1. [if applicable] Address immediate safety concerns. For example, if the user discusses committing a violent\\ncrime, the model should point them towards law enforcement resources.\\n2. Address the prompt. the model should refuse to answer the prompt as given, stating that it violates its\\npolicy to commit, advise or give information on illegal activities.\\n3. Add context and additional information. If applicable, the model can advise on legal alternatives.\\n4. Encourage users to ask for/view additional info as appropriate. If applicable, the model can encourage the\\nuser to refine their prompt so that it does not contain any illegal requests or activities.\\n(Based on a specific risk category) The following is a question that can elicit unsafe behavior from you. The\\nquestion was classified as belonging to the violating category: ‘Explicit Content’. You should answer using\\nthe following template:\\n1. Address immediate safety concerns. For example, if a prompt states the user is a victim of violence or\\nabuse, the model should provide support resources in an empathetic tone.\\n2. Address the prompt. the model should refuse to generate explicit sexual or violent content, stating that to\\ndo so would violate its policies.\\nTable 39: Safe preprompts for context distillation. We use various preprompts for context distillation, some\\ninspired from Bai et al. (2022b) and others from our own creation. We also use preprompts that are targeted\\ntowards specific prompts that we have assigned to certain risk categories (see bottom two examples).\\n64', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8539883593726021)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_with_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import QueryBundle\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from typing import Any, List\n",
    "\n",
    "\n",
    "class VectorDBRetriever(BaseRetriever):\n",
    "    \"\"\"Retriever over a postgres vector store.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vector_store: DuckDBVectorStore,\n",
    "        embed_model: Any,\n",
    "        query_mode: str = \"default\",\n",
    "        similarity_top_k: int = 2,\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        self._vector_store = vector_store\n",
    "        self._embed_model = embed_model\n",
    "        self._query_mode = query_mode\n",
    "        self._similarity_top_k = similarity_top_k\n",
    "        super().__init__()\n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve.\"\"\"\n",
    "        query_embedding = embed_model.get_query_embedding(\n",
    "            query_bundle.query_str\n",
    "        )\n",
    "        vector_store_query = VectorStoreQuery(\n",
    "            query_embedding=query_embedding,\n",
    "            similarity_top_k=self._similarity_top_k,\n",
    "            mode=self._query_mode,\n",
    "        )\n",
    "        query_result = vector_store.query(vector_store_query)\n",
    "\n",
    "        nodes_with_scores = []\n",
    "        for index, node in enumerate(query_result.nodes):\n",
    "            score: Optional[float] = None\n",
    "            if query_result.similarities is not None:\n",
    "                score = query_result.similarities[index]\n",
    "            nodes_with_scores.append(NodeWithScore(node=node, score=score))\n",
    "\n",
    "        return nodes_with_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = VectorDBRetriever(\n",
    "    vector_store, embed_model, query_mode=\"default\", similarity_top_k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index.llms.llama_cpp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquery_engine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RetrieverQueryEngine\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllama_cpp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlamaCPP\n\u001b[1;32m      4\u001b[0m model_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF/resolve/main/llama-2-13b-chat.Q4_0.gguf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m llm \u001b[38;5;241m=\u001b[39m LlamaCPP(\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# You can pass in the URL to a GGML model to download it automatically\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     model_url\u001b[38;5;241m=\u001b[39mmodel_url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama_index.llms.llama_cpp'"
     ]
    }
   ],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.llms.llama_cpp import LlamaCPP\n",
    "\n",
    "model_url = \"https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF/resolve/main/llama-2-13b-chat.Q4_0.gguf\"\n",
    "\n",
    "llm = LlamaCPP(\n",
    "    # You can pass in the URL to a GGML model to download it automatically\n",
    "    model_url=model_url,\n",
    "    # optionally, you can set the path to a pre-downloaded model instead of model_url\n",
    "    model_path=None,\n",
    "    temperature=0.1,\n",
    "    max_new_tokens=100,\n",
    "    context_window=3900,\n",
    "    generate_kwargs={},\n",
    "    # model_kwargs={\"n_gpu_layers\": 1},\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(retriever, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
